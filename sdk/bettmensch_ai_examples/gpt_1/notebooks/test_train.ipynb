{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0301 01:48:55.898000 18592 torch\\distributed\\elastic\\multiprocessing\\redirects.py:27] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "c:\\Users\\scher\\Repositories\\bettmensch.ai-examples\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D5027EBD0>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D5027EBD0>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D5027EBD0>\n",
      "Pipeline pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D5027EBD0>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D5027EBD0>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D5027EBD0>\n",
      "Pipeline pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D5027EBD0>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D5027EBD0>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D5027EBD0>\n",
      "Pipeline pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D5027EBD0>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D5027EBD0>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D5027EBD0>\n"
     ]
    }
   ],
   "source": [
    "from bettmensch_ai.pipelines import OutputArtifact, InputArtifact\n",
    "import torch\n",
    "from bettmensch_ai_examples.gpt_1.src.train import pretrain, GPTPretrainConfig, GPTTrainer, TokenizedBookCorpusOpenSplit\n",
    "from bettmensch_ai_examples.gpt_1.component import get_source_data_split, get_tokenized_data_split_and_tokenizer, pretrain_and_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_source_data = False\n",
    "\n",
    "if get_source_data:\n",
    "    get_source_data_split(\n",
    "        data_out=OutputArtifact(name=\"source_data_train\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data = False\n",
    "N_TOTAL = 74004228\n",
    "train_split = 0.9\n",
    "n_train_observations = int(train_split * N_TOTAL)\n",
    "sequence_length_test = 128\n",
    "\n",
    "if preprocess_data:\n",
    "    get_tokenized_data_split_and_tokenizer(\n",
    "        source_data_split=InputArtifact(name=\"source_data_train\"),\n",
    "        end_index=n_train_observations,\n",
    "        sequence_length=sequence_length_test,\n",
    "        tokenized_data_out=OutputArtifact(name=\"tokenized_data_train\"),\n",
    "        tokenizer_out=OutputArtifact(name=\"tokenizer_train\")\n",
    "    )\n",
    "\n",
    "    get_tokenized_data_split_and_tokenizer(\n",
    "        source_data_split=InputArtifact(name=\"source_data_train\"),\n",
    "        start_index=n_train_observations,\n",
    "        end_index=-1,\n",
    "        sequence_length=sequence_length_test,\n",
    "        tokenized_data_out=OutputArtifact(name=\"tokenized_data_validation\"),\n",
    "        tokenizer_out=OutputArtifact(name=\"tokenizer_validation\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'dataset': {'path': 'tokenized_data_validation', 'context_size': 128}, 'dataloader': {'batch_size': 45, 'shuffle': True}}, 'validation': {'use': True, 'dataset': {'path': 'tokenized_data_validation', 'context_size': 128}, 'dataloader': {'batch_size': 80, 'shuffle': False}}}\n",
      "{'path': 'tokenizer_train'}\n",
      "{'architecture': {'n_tokens': 128, 'dim_embed': 768, 'n_decoder_layers': 12, 'n_heads': 12, 'dropout': 0.1}, 'misc': {'verbose': False}}\n",
      "{'optimizer': {'lr': 0.00025, 'weight_decay': 0.01, 'betas': [0.9, 0.95], 'eps': 0.0001}, 'scheduler': {'linear': {'start_factor': 0.0001, 'end_factor': 1, 'total_iters': 2000}, 'cosine': {'T_max': 500, 'eta_min': 0}, 'sequential': {'milestones': [2000]}}, 'training': {'grad_clip_norm': 1.0, 'n_steps': 1000000, 'eval_steps': 50, 'n_steps_eval': 10, 'checkpoint_steps': 7500}}\n"
     ]
    }
   ],
   "source": [
    "config_test = GPTPretrainConfig.from_file(\"C:\\\\Users\\\\scher\\\\Repositories\\\\bettmensch.ai-examples\\\\sdk\\\\bettmensch_ai_examples\\\\gpt_1\\\\src\\\\config.yaml\")\n",
    "print(config_test.data)\n",
    "print(config_test.tokenizer)\n",
    "print(config_test.model)\n",
    "print(config_test.trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-01 01:50:18 | Step 50/1000000 | Train loss: 10.40625 | Validation loss: 11.0 | Learning rate: 6.274375000000002e-06\n",
      "2025-03-01 01:51:19 | Step 100/1000000 | Train loss: 10.1125 | Validation loss: 10.83125 | Learning rate: 1.252375e-05\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "\n",
    "if train:\n",
    "    pretrain(config_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5:\n",
      "2025-02-28 10:36:41 | Batch 10/18424 (observations 405-450/829080) loss: 4.1578125\n",
      "2025-02-28 10:37:00 | Batch 20/18424 (observations 855-900/829080) loss: 4.18125\n",
      "2025-02-28 10:37:18 | Batch 30/18424 (observations 1305-1350/829080) loss: 4.0984375\n",
      "2025-02-28 10:37:37 | Batch 40/18424 (observations 1755-1800/829080) loss: 4.115625\n",
      "2025-02-28 10:37:56 | Batch 50/18424 (observations 2205-2250/829080) loss: 4.146875\n",
      "2025-02-28 10:38:14 | Batch 60/18424 (observations 2655-2700/829080) loss: 4.134375\n",
      "2025-02-28 10:38:32 | Batch 70/18424 (observations 3105-3150/829080) loss: 4.134375\n",
      "2025-02-28 10:38:51 | Batch 80/18424 (observations 3555-3600/829080) loss: 4.18125\n",
      "2025-02-28 10:39:09 | Batch 90/18424 (observations 4005-4050/829080) loss: 4.1375\n",
      "2025-02-28 10:39:28 | Batch 100/18424 (observations 4455-4500/829080) loss: 4.1140625\n",
      "2025-02-28 10:39:46 | Batch 110/18424 (observations 4905-4950/829080) loss: 4.14375\n",
      "2025-02-28 10:40:05 | Batch 120/18424 (observations 5355-5400/829080) loss: 4.1125\n",
      "2025-02-28 10:40:24 | Batch 130/18424 (observations 5805-5850/829080) loss: 4.109375\n",
      "2025-02-28 10:40:42 | Batch 140/18424 (observations 6255-6300/829080) loss: 4.175\n",
      "2025-02-28 10:41:01 | Batch 150/18424 (observations 6705-6750/829080) loss: 4.1390625\n",
      "2025-02-28 10:41:19 | Batch 160/18424 (observations 7155-7200/829080) loss: 4.0921875\n",
      "2025-02-28 10:41:37 | Batch 170/18424 (observations 7605-7650/829080) loss: 4.090625\n",
      "2025-02-28 10:41:56 | Batch 180/18424 (observations 8055-8100/829080) loss: 4.165625\n",
      "2025-02-28 10:42:14 | Batch 190/18424 (observations 8505-8550/829080) loss: 4.1546875\n",
      "2025-02-28 10:42:32 | Batch 200/18424 (observations 8955-9000/829080) loss: 4.190625\n",
      "2025-02-28 10:42:51 | Batch 210/18424 (observations 9405-9450/829080) loss: 4.153125\n",
      "2025-02-28 10:43:09 | Batch 220/18424 (observations 9855-9900/829080) loss: 4.121875\n",
      "2025-02-28 10:43:28 | Batch 230/18424 (observations 10305-10350/829080) loss: 4.1046875\n",
      "2025-02-28 10:43:46 | Batch 240/18424 (observations 10755-10800/829080) loss: 4.09375\n",
      "2025-02-28 10:44:05 | Batch 250/18424 (observations 11205-11250/829080) loss: 4.153125\n",
      "2025-02-28 10:44:23 | Batch 260/18424 (observations 11655-11700/829080) loss: 4.1875\n",
      "2025-02-28 10:44:41 | Batch 270/18424 (observations 12105-12150/829080) loss: 4.1609375\n",
      "2025-02-28 10:45:00 | Batch 280/18424 (observations 12555-12600/829080) loss: 4.140625\n",
      "2025-02-28 10:45:19 | Batch 290/18424 (observations 13005-13050/829080) loss: 4.165625\n",
      "2025-02-28 10:45:38 | Batch 300/18424 (observations 13455-13500/829080) loss: 4.096875\n",
      "2025-02-28 10:45:57 | Batch 310/18424 (observations 13905-13950/829080) loss: 4.1\n",
      "2025-02-28 10:46:16 | Batch 320/18424 (observations 14355-14400/829080) loss: 4.128125\n",
      "2025-02-28 10:46:36 | Batch 330/18424 (observations 14805-14850/829080) loss: 4.0828125\n",
      "2025-02-28 10:46:54 | Batch 340/18424 (observations 15255-15300/829080) loss: 4.1203125\n",
      "2025-02-28 10:47:13 | Batch 350/18424 (observations 15705-15750/829080) loss: 4.1453125\n",
      "2025-02-28 10:47:32 | Batch 360/18424 (observations 16155-16200/829080) loss: 4.1625\n",
      "2025-02-28 10:47:50 | Batch 370/18424 (observations 16605-16650/829080) loss: 4.140625\n",
      "2025-02-28 10:48:08 | Batch 380/18424 (observations 17055-17100/829080) loss: 4.1375\n",
      "2025-02-28 10:48:27 | Batch 390/18424 (observations 17505-17550/829080) loss: 4.1453125\n",
      "2025-02-28 10:48:45 | Batch 400/18424 (observations 17955-18000/829080) loss: 4.15\n",
      "2025-02-28 10:49:04 | Batch 410/18424 (observations 18405-18450/829080) loss: 4.16875\n",
      "2025-02-28 10:49:22 | Batch 420/18424 (observations 18855-18900/829080) loss: 4.1578125\n",
      "2025-02-28 10:49:41 | Batch 430/18424 (observations 19305-19350/829080) loss: 4.1390625\n",
      "2025-02-28 10:50:00 | Batch 440/18424 (observations 19755-19800/829080) loss: 4.0875\n",
      "2025-02-28 10:50:18 | Batch 450/18424 (observations 20205-20250/829080) loss: 4.1296875\n",
      "2025-02-28 10:50:37 | Batch 460/18424 (observations 20655-20700/829080) loss: 4.146875\n",
      "2025-02-28 10:50:55 | Batch 470/18424 (observations 21105-21150/829080) loss: 4.178125\n",
      "2025-02-28 10:51:13 | Batch 480/18424 (observations 21555-21600/829080) loss: 4.0703125\n",
      "2025-02-28 10:51:32 | Batch 490/18424 (observations 22005-22050/829080) loss: 4.0890625\n",
      "2025-02-28 10:51:50 | Batch 500/18424 (observations 22455-22500/829080) loss: 4.1203125\n",
      "2025-02-28 10:52:09 | Batch 510/18424 (observations 22905-22950/829080) loss: 4.1625\n",
      "2025-02-28 10:52:28 | Batch 520/18424 (observations 23355-23400/829080) loss: 4.0984375\n",
      "2025-02-28 10:52:46 | Batch 530/18424 (observations 23805-23850/829080) loss: 4.125\n",
      "2025-02-28 10:53:05 | Batch 540/18424 (observations 24255-24300/829080) loss: 4.153125\n",
      "2025-02-28 10:53:24 | Batch 550/18424 (observations 24705-24750/829080) loss: 4.1390625\n",
      "2025-02-28 10:53:42 | Batch 560/18424 (observations 25155-25200/829080) loss: 4.1\n",
      "2025-02-28 10:54:01 | Batch 570/18424 (observations 25605-25650/829080) loss: 4.140625\n",
      "2025-02-28 10:54:19 | Batch 580/18424 (observations 26055-26100/829080) loss: 4.103125\n",
      "2025-02-28 10:54:38 | Batch 590/18424 (observations 26505-26550/829080) loss: 4.10625\n",
      "2025-02-28 10:54:56 | Batch 600/18424 (observations 26955-27000/829080) loss: 4.1375\n",
      "2025-02-28 10:55:15 | Batch 610/18424 (observations 27405-27450/829080) loss: 4.11875\n",
      "2025-02-28 10:55:33 | Batch 620/18424 (observations 27855-27900/829080) loss: 4.121875\n",
      "2025-02-28 10:55:51 | Batch 630/18424 (observations 28305-28350/829080) loss: 4.096875\n",
      "2025-02-28 10:56:10 | Batch 640/18424 (observations 28755-28800/829080) loss: 4.1109375\n",
      "2025-02-28 10:56:28 | Batch 650/18424 (observations 29205-29250/829080) loss: 4.109375\n",
      "2025-02-28 10:56:47 | Batch 660/18424 (observations 29655-29700/829080) loss: 4.1359375\n",
      "2025-02-28 10:57:05 | Batch 670/18424 (observations 30105-30150/829080) loss: 4.18125\n",
      "2025-02-28 10:57:24 | Batch 680/18424 (observations 30555-30600/829080) loss: 4.203125\n",
      "2025-02-28 10:57:43 | Batch 690/18424 (observations 31005-31050/829080) loss: 4.1375\n",
      "2025-02-28 10:58:01 | Batch 700/18424 (observations 31455-31500/829080) loss: 4.096875\n",
      "2025-02-28 10:58:19 | Batch 710/18424 (observations 31905-31950/829080) loss: 4.1296875\n",
      "2025-02-28 10:58:37 | Batch 720/18424 (observations 32355-32400/829080) loss: 4.0984375\n",
      "2025-02-28 10:58:55 | Batch 730/18424 (observations 32805-32850/829080) loss: 4.14375\n",
      "2025-02-28 10:59:13 | Batch 740/18424 (observations 33255-33300/829080) loss: 4.06875\n",
      "2025-02-28 10:59:32 | Batch 750/18424 (observations 33705-33750/829080) loss: 4.115625\n",
      "2025-02-28 10:59:50 | Batch 760/18424 (observations 34155-34200/829080) loss: 4.1421875\n",
      "2025-02-28 11:00:08 | Batch 770/18424 (observations 34605-34650/829080) loss: 4.146875\n",
      "2025-02-28 11:00:27 | Batch 780/18424 (observations 35055-35100/829080) loss: 4.103125\n",
      "2025-02-28 11:00:45 | Batch 790/18424 (observations 35505-35550/829080) loss: 4.1265625\n",
      "2025-02-28 11:01:04 | Batch 800/18424 (observations 35955-36000/829080) loss: 4.128125\n",
      "2025-02-28 11:01:23 | Batch 810/18424 (observations 36405-36450/829080) loss: 4.1078125\n",
      "2025-02-28 11:01:42 | Batch 820/18424 (observations 36855-36900/829080) loss: 4.1265625\n",
      "2025-02-28 11:02:01 | Batch 830/18424 (observations 37305-37350/829080) loss: 4.0875\n",
      "2025-02-28 11:02:20 | Batch 840/18424 (observations 37755-37800/829080) loss: 4.140625\n",
      "2025-02-28 11:02:38 | Batch 850/18424 (observations 38205-38250/829080) loss: 4.153125\n",
      "2025-02-28 11:02:57 | Batch 860/18424 (observations 38655-38700/829080) loss: 4.0859375\n",
      "2025-02-28 11:03:15 | Batch 870/18424 (observations 39105-39150/829080) loss: 4.146875\n",
      "2025-02-28 11:03:33 | Batch 880/18424 (observations 39555-39600/829080) loss: 4.140625\n",
      "2025-02-28 11:03:51 | Batch 890/18424 (observations 40005-40050/829080) loss: 4.0546875\n",
      "2025-02-28 11:04:10 | Batch 900/18424 (observations 40455-40500/829080) loss: 4.0875\n",
      "2025-02-28 11:04:28 | Batch 910/18424 (observations 40905-40950/829080) loss: 4.15\n",
      "2025-02-28 11:04:46 | Batch 920/18424 (observations 41355-41400/829080) loss: 4.19375\n",
      "2025-02-28 11:05:05 | Batch 930/18424 (observations 41805-41850/829080) loss: 4.153125\n",
      "2025-02-28 11:05:24 | Batch 940/18424 (observations 42255-42300/829080) loss: 4.125\n",
      "2025-02-28 11:05:43 | Batch 950/18424 (observations 42705-42750/829080) loss: 4.1453125\n",
      "2025-02-28 11:06:01 | Batch 960/18424 (observations 43155-43200/829080) loss: 4.178125\n",
      "2025-02-28 11:06:20 | Batch 970/18424 (observations 43605-43650/829080) loss: 4.1125\n",
      "2025-02-28 11:06:38 | Batch 980/18424 (observations 44055-44100/829080) loss: 4.0703125\n",
      "2025-02-28 11:06:57 | Batch 990/18424 (observations 44505-44550/829080) loss: 4.13125\n",
      "2025-02-28 11:07:15 | Batch 1000/18424 (observations 44955-45000/829080) loss: 4.175\n",
      "2025-02-28 11:07:34 | Batch 1010/18424 (observations 45405-45450/829080) loss: 4.1484375\n",
      "2025-02-28 11:07:52 | Batch 1020/18424 (observations 45855-45900/829080) loss: 4.184375\n",
      "2025-02-28 11:08:11 | Batch 1030/18424 (observations 46305-46350/829080) loss: 4.128125\n",
      "2025-02-28 11:08:29 | Batch 1040/18424 (observations 46755-46800/829080) loss: 4.0984375\n",
      "2025-02-28 11:08:47 | Batch 1050/18424 (observations 47205-47250/829080) loss: 4.14375\n",
      "2025-02-28 11:09:06 | Batch 1060/18424 (observations 47655-47700/829080) loss: 4.175\n",
      "2025-02-28 11:09:24 | Batch 1070/18424 (observations 48105-48150/829080) loss: 4.1234375\n",
      "2025-02-28 11:09:43 | Batch 1080/18424 (observations 48555-48600/829080) loss: 4.103125\n",
      "2025-02-28 11:10:01 | Batch 1090/18424 (observations 49005-49050/829080) loss: 4.125\n",
      "2025-02-28 11:10:20 | Batch 1100/18424 (observations 49455-49500/829080) loss: 4.096875\n",
      "2025-02-28 11:10:38 | Batch 1110/18424 (observations 49905-49950/829080) loss: 4.1125\n",
      "2025-02-28 11:10:57 | Batch 1120/18424 (observations 50355-50400/829080) loss: 4.171875\n",
      "2025-02-28 11:11:15 | Batch 1130/18424 (observations 50805-50850/829080) loss: 4.1375\n",
      "2025-02-28 11:11:33 | Batch 1140/18424 (observations 51255-51300/829080) loss: 4.128125\n",
      "2025-02-28 11:11:52 | Batch 1150/18424 (observations 51705-51750/829080) loss: 4.0578125\n",
      "2025-02-28 11:12:10 | Batch 1160/18424 (observations 52155-52200/829080) loss: 4.1640625\n",
      "2025-02-28 11:12:29 | Batch 1170/18424 (observations 52605-52650/829080) loss: 4.1328125\n",
      "2025-02-28 11:12:47 | Batch 1180/18424 (observations 53055-53100/829080) loss: 4.11875\n",
      "2025-02-28 11:13:06 | Batch 1190/18424 (observations 53505-53550/829080) loss: 4.14375\n",
      "2025-02-28 11:13:24 | Batch 1200/18424 (observations 53955-54000/829080) loss: 4.1625\n",
      "2025-02-28 11:13:42 | Batch 1210/18424 (observations 54405-54450/829080) loss: 4.16875\n",
      "2025-02-28 11:14:01 | Batch 1220/18424 (observations 54855-54900/829080) loss: 4.140625\n",
      "2025-02-28 11:14:19 | Batch 1230/18424 (observations 55305-55350/829080) loss: 4.14375\n",
      "2025-02-28 11:14:38 | Batch 1240/18424 (observations 55755-55800/829080) loss: 4.1796875\n",
      "2025-02-28 11:14:57 | Batch 1250/18424 (observations 56205-56250/829080) loss: 4.0953125\n",
      "2025-02-28 11:15:15 | Batch 1260/18424 (observations 56655-56700/829080) loss: 4.165625\n",
      "2025-02-28 11:15:34 | Batch 1270/18424 (observations 57105-57150/829080) loss: 4.1625\n",
      "2025-02-28 11:15:52 | Batch 1280/18424 (observations 57555-57600/829080) loss: 4.134375\n",
      "2025-02-28 11:16:11 | Batch 1290/18424 (observations 58005-58050/829080) loss: 4.1203125\n",
      "2025-02-28 11:16:29 | Batch 1300/18424 (observations 58455-58500/829080) loss: 4.109375\n",
      "2025-02-28 11:16:48 | Batch 1310/18424 (observations 58905-58950/829080) loss: 4.159375\n",
      "2025-02-28 11:17:06 | Batch 1320/18424 (observations 59355-59400/829080) loss: 4.1359375\n",
      "2025-02-28 11:17:25 | Batch 1330/18424 (observations 59805-59850/829080) loss: 4.175\n",
      "2025-02-28 11:17:43 | Batch 1340/18424 (observations 60255-60300/829080) loss: 4.1625\n",
      "2025-02-28 11:18:02 | Batch 1350/18424 (observations 60705-60750/829080) loss: 4.1234375\n",
      "2025-02-28 11:18:20 | Batch 1360/18424 (observations 61155-61200/829080) loss: 4.153125\n",
      "2025-02-28 11:18:39 | Batch 1370/18424 (observations 61605-61650/829080) loss: 4.125\n",
      "2025-02-28 11:18:58 | Batch 1380/18424 (observations 62055-62100/829080) loss: 4.153125\n",
      "2025-02-28 11:19:16 | Batch 1390/18424 (observations 62505-62550/829080) loss: 4.1421875\n",
      "2025-02-28 11:19:35 | Batch 1400/18424 (observations 62955-63000/829080) loss: 4.1265625\n",
      "2025-02-28 11:19:53 | Batch 1410/18424 (observations 63405-63450/829080) loss: 4.159375\n",
      "2025-02-28 11:20:12 | Batch 1420/18424 (observations 63855-63900/829080) loss: 4.1265625\n",
      "2025-02-28 11:20:30 | Batch 1430/18424 (observations 64305-64350/829080) loss: 4.15625\n",
      "2025-02-28 11:20:49 | Batch 1440/18424 (observations 64755-64800/829080) loss: 4.165625\n",
      "2025-02-28 11:21:07 | Batch 1450/18424 (observations 65205-65250/829080) loss: 4.15\n",
      "2025-02-28 11:21:26 | Batch 1460/18424 (observations 65655-65700/829080) loss: 4.14375\n",
      "2025-02-28 11:21:44 | Batch 1470/18424 (observations 66105-66150/829080) loss: 4.0984375\n",
      "2025-02-28 11:22:03 | Batch 1480/18424 (observations 66555-66600/829080) loss: 4.1421875\n",
      "2025-02-28 11:22:21 | Batch 1490/18424 (observations 67005-67050/829080) loss: 4.153125\n",
      "2025-02-28 11:22:39 | Batch 1500/18424 (observations 67455-67500/829080) loss: 4.134375\n",
      "2025-02-28 11:22:58 | Batch 1510/18424 (observations 67905-67950/829080) loss: 4.1296875\n",
      "2025-02-28 11:23:16 | Batch 1520/18424 (observations 68355-68400/829080) loss: 4.140625\n",
      "2025-02-28 11:23:35 | Batch 1530/18424 (observations 68805-68850/829080) loss: 4.165625\n",
      "2025-02-28 11:23:53 | Batch 1540/18424 (observations 69255-69300/829080) loss: 4.1609375\n",
      "2025-02-28 11:24:12 | Batch 1550/18424 (observations 69705-69750/829080) loss: 4.0859375\n",
      "2025-02-28 11:24:31 | Batch 1560/18424 (observations 70155-70200/829080) loss: 4.178125\n",
      "2025-02-28 11:24:49 | Batch 1570/18424 (observations 70605-70650/829080) loss: 4.121875\n",
      "2025-02-28 11:25:08 | Batch 1580/18424 (observations 71055-71100/829080) loss: 4.125\n",
      "2025-02-28 11:25:26 | Batch 1590/18424 (observations 71505-71550/829080) loss: 4.14375\n",
      "2025-02-28 11:25:44 | Batch 1600/18424 (observations 71955-72000/829080) loss: 4.109375\n",
      "2025-02-28 11:26:03 | Batch 1610/18424 (observations 72405-72450/829080) loss: 4.10625\n",
      "2025-02-28 11:26:21 | Batch 1620/18424 (observations 72855-72900/829080) loss: 4.078125\n",
      "2025-02-28 11:26:40 | Batch 1630/18424 (observations 73305-73350/829080) loss: 4.096875\n",
      "2025-02-28 11:26:58 | Batch 1640/18424 (observations 73755-73800/829080) loss: 4.0890625\n",
      "2025-02-28 11:27:17 | Batch 1650/18424 (observations 74205-74250/829080) loss: 4.1\n",
      "2025-02-28 11:27:35 | Batch 1660/18424 (observations 74655-74700/829080) loss: 4.140625\n",
      "2025-02-28 11:27:54 | Batch 1670/18424 (observations 75105-75150/829080) loss: 4.065625\n",
      "2025-02-28 11:28:12 | Batch 1680/18424 (observations 75555-75600/829080) loss: 4.140625\n",
      "2025-02-28 11:28:30 | Batch 1690/18424 (observations 76005-76050/829080) loss: 4.0734375\n",
      "2025-02-28 11:28:49 | Batch 1700/18424 (observations 76455-76500/829080) loss: 4.2\n",
      "2025-02-28 11:29:07 | Batch 1710/18424 (observations 76905-76950/829080) loss: 4.0796875\n",
      "2025-02-28 11:29:26 | Batch 1720/18424 (observations 77355-77400/829080) loss: 4.125\n",
      "2025-02-28 11:29:44 | Batch 1730/18424 (observations 77805-77850/829080) loss: 4.078125\n",
      "2025-02-28 11:30:03 | Batch 1740/18424 (observations 78255-78300/829080) loss: 4.121875\n",
      "2025-02-28 11:30:21 | Batch 1750/18424 (observations 78705-78750/829080) loss: 4.1171875\n",
      "2025-02-28 11:30:40 | Batch 1760/18424 (observations 79155-79200/829080) loss: 4.1171875\n",
      "2025-02-28 11:30:58 | Batch 1770/18424 (observations 79605-79650/829080) loss: 4.1390625\n",
      "2025-02-28 11:31:16 | Batch 1780/18424 (observations 80055-80100/829080) loss: 4.1203125\n",
      "2025-02-28 11:31:35 | Batch 1790/18424 (observations 80505-80550/829080) loss: 4.115625\n",
      "2025-02-28 11:31:53 | Batch 1800/18424 (observations 80955-81000/829080) loss: 4.134375\n",
      "2025-02-28 11:32:12 | Batch 1810/18424 (observations 81405-81450/829080) loss: 4.1328125\n",
      "2025-02-28 11:32:30 | Batch 1820/18424 (observations 81855-81900/829080) loss: 4.1109375\n",
      "2025-02-28 11:32:49 | Batch 1830/18424 (observations 82305-82350/829080) loss: 4.1171875\n",
      "2025-02-28 11:33:08 | Batch 1840/18424 (observations 82755-82800/829080) loss: 4.128125\n",
      "2025-02-28 11:33:26 | Batch 1850/18424 (observations 83205-83250/829080) loss: 4.20625\n",
      "2025-02-28 11:33:45 | Batch 1860/18424 (observations 83655-83700/829080) loss: 4.1046875\n",
      "2025-02-28 11:34:03 | Batch 1870/18424 (observations 84105-84150/829080) loss: 4.09375\n",
      "2025-02-28 11:34:22 | Batch 1880/18424 (observations 84555-84600/829080) loss: 4.21875\n",
      "2025-02-28 11:34:40 | Batch 1890/18424 (observations 85005-85050/829080) loss: 4.13125\n",
      "2025-02-28 11:34:58 | Batch 1900/18424 (observations 85455-85500/829080) loss: 4.0875\n",
      "2025-02-28 11:35:17 | Batch 1910/18424 (observations 85905-85950/829080) loss: 4.0984375\n",
      "2025-02-28 11:35:35 | Batch 1920/18424 (observations 86355-86400/829080) loss: 4.0875\n",
      "2025-02-28 11:35:54 | Batch 1930/18424 (observations 86805-86850/829080) loss: 4.05\n",
      "2025-02-28 11:36:12 | Batch 1940/18424 (observations 87255-87300/829080) loss: 4.1015625\n",
      "2025-02-28 11:36:30 | Batch 1950/18424 (observations 87705-87750/829080) loss: 4.10625\n",
      "2025-02-28 11:36:49 | Batch 1960/18424 (observations 88155-88200/829080) loss: 4.11875\n",
      "2025-02-28 11:37:07 | Batch 1970/18424 (observations 88605-88650/829080) loss: 4.0734375\n",
      "2025-02-28 11:37:26 | Batch 1980/18424 (observations 89055-89100/829080) loss: 4.090625\n",
      "2025-02-28 11:37:44 | Batch 1990/18424 (observations 89505-89550/829080) loss: 4.1328125\n",
      "2025-02-28 11:38:03 | Batch 2000/18424 (observations 89955-90000/829080) loss: 4.090625\n",
      "2025-02-28 11:38:21 | Batch 2010/18424 (observations 90405-90450/829080) loss: 4.1484375\n",
      "2025-02-28 11:38:39 | Batch 2020/18424 (observations 90855-90900/829080) loss: 4.0953125\n",
      "2025-02-28 11:38:58 | Batch 2030/18424 (observations 91305-91350/829080) loss: 4.1265625\n",
      "2025-02-28 11:39:16 | Batch 2040/18424 (observations 91755-91800/829080) loss: 4.0640625\n",
      "2025-02-28 11:39:35 | Batch 2050/18424 (observations 92205-92250/829080) loss: 4.10625\n",
      "2025-02-28 11:39:53 | Batch 2060/18424 (observations 92655-92700/829080) loss: 4.14375\n",
      "2025-02-28 11:40:12 | Batch 2070/18424 (observations 93105-93150/829080) loss: 4.0875\n",
      "2025-02-28 11:40:30 | Batch 2080/18424 (observations 93555-93600/829080) loss: 4.0765625\n",
      "2025-02-28 11:40:48 | Batch 2090/18424 (observations 94005-94050/829080) loss: 4.153125\n",
      "2025-02-28 11:41:07 | Batch 2100/18424 (observations 94455-94500/829080) loss: 4.125\n",
      "2025-02-28 11:41:25 | Batch 2110/18424 (observations 94905-94950/829080) loss: 4.159375\n",
      "2025-02-28 11:41:44 | Batch 2120/18424 (observations 95355-95400/829080) loss: 4.09375\n",
      "2025-02-28 11:42:02 | Batch 2130/18424 (observations 95805-95850/829080) loss: 4.096875\n",
      "2025-02-28 11:42:21 | Batch 2140/18424 (observations 96255-96300/829080) loss: 4.1671875\n",
      "2025-02-28 11:42:39 | Batch 2150/18424 (observations 96705-96750/829080) loss: 4.121875\n",
      "2025-02-28 11:42:57 | Batch 2160/18424 (observations 97155-97200/829080) loss: 4.09375\n",
      "2025-02-28 11:43:16 | Batch 2170/18424 (observations 97605-97650/829080) loss: 4.134375\n",
      "2025-02-28 11:43:34 | Batch 2180/18424 (observations 98055-98100/829080) loss: 4.096875\n",
      "2025-02-28 11:43:53 | Batch 2190/18424 (observations 98505-98550/829080) loss: 4.0921875\n",
      "2025-02-28 11:44:11 | Batch 2200/18424 (observations 98955-99000/829080) loss: 4.18125\n",
      "2025-02-28 11:44:30 | Batch 2210/18424 (observations 99405-99450/829080) loss: 4.115625\n",
      "2025-02-28 11:44:48 | Batch 2220/18424 (observations 99855-99900/829080) loss: 4.1609375\n",
      "2025-02-28 11:45:06 | Batch 2230/18424 (observations 100305-100350/829080) loss: 4.1625\n",
      "2025-02-28 11:45:25 | Batch 2240/18424 (observations 100755-100800/829080) loss: 4.16875\n",
      "2025-02-28 11:45:43 | Batch 2250/18424 (observations 101205-101250/829080) loss: 4.1375\n",
      "2025-02-28 11:46:02 | Batch 2260/18424 (observations 101655-101700/829080) loss: 4.1375\n",
      "2025-02-28 11:46:20 | Batch 2270/18424 (observations 102105-102150/829080) loss: 4.1015625\n",
      "2025-02-28 11:46:39 | Batch 2280/18424 (observations 102555-102600/829080) loss: 4.11875\n",
      "2025-02-28 11:46:57 | Batch 2290/18424 (observations 103005-103050/829080) loss: 4.1125\n",
      "2025-02-28 11:47:15 | Batch 2300/18424 (observations 103455-103500/829080) loss: 4.1625\n",
      "2025-02-28 11:47:34 | Batch 2310/18424 (observations 103905-103950/829080) loss: 4.2125\n",
      "2025-02-28 11:47:52 | Batch 2320/18424 (observations 104355-104400/829080) loss: 4.115625\n",
      "2025-02-28 11:48:11 | Batch 2330/18424 (observations 104805-104850/829080) loss: 4.19375\n",
      "2025-02-28 11:48:29 | Batch 2340/18424 (observations 105255-105300/829080) loss: 4.1046875\n",
      "2025-02-28 11:48:47 | Batch 2350/18424 (observations 105705-105750/829080) loss: 4.15\n",
      "2025-02-28 11:49:06 | Batch 2360/18424 (observations 106155-106200/829080) loss: 4.1375\n",
      "2025-02-28 11:49:24 | Batch 2370/18424 (observations 106605-106650/829080) loss: 4.1046875\n",
      "2025-02-28 11:49:43 | Batch 2380/18424 (observations 107055-107100/829080) loss: 4.184375\n",
      "2025-02-28 11:50:01 | Batch 2390/18424 (observations 107505-107550/829080) loss: 4.075\n",
      "2025-02-28 11:50:20 | Batch 2400/18424 (observations 107955-108000/829080) loss: 4.053125\n",
      "2025-02-28 11:50:38 | Batch 2410/18424 (observations 108405-108450/829080) loss: 4.171875\n",
      "2025-02-28 11:50:56 | Batch 2420/18424 (observations 108855-108900/829080) loss: 4.125\n",
      "2025-02-28 11:51:15 | Batch 2430/18424 (observations 109305-109350/829080) loss: 4.153125\n",
      "2025-02-28 11:51:33 | Batch 2440/18424 (observations 109755-109800/829080) loss: 4.0984375\n",
      "2025-02-28 11:51:52 | Batch 2450/18424 (observations 110205-110250/829080) loss: 4.13125\n",
      "2025-02-28 11:52:10 | Batch 2460/18424 (observations 110655-110700/829080) loss: 4.096875\n",
      "2025-02-28 11:52:29 | Batch 2470/18424 (observations 111105-111150/829080) loss: 4.1390625\n",
      "2025-02-28 11:52:47 | Batch 2480/18424 (observations 111555-111600/829080) loss: 4.084375\n",
      "2025-02-28 11:53:05 | Batch 2490/18424 (observations 112005-112050/829080) loss: 4.1671875\n",
      "2025-02-28 11:53:24 | Batch 2500/18424 (observations 112455-112500/829080) loss: 4.125\n",
      "2025-02-28 11:53:42 | Batch 2510/18424 (observations 112905-112950/829080) loss: 4.171875\n",
      "2025-02-28 11:54:01 | Batch 2520/18424 (observations 113355-113400/829080) loss: 4.1625\n",
      "2025-02-28 11:54:19 | Batch 2530/18424 (observations 113805-113850/829080) loss: 4.1078125\n",
      "2025-02-28 11:54:38 | Batch 2540/18424 (observations 114255-114300/829080) loss: 4.16875\n",
      "2025-02-28 11:54:56 | Batch 2550/18424 (observations 114705-114750/829080) loss: 4.1265625\n",
      "2025-02-28 11:55:14 | Batch 2560/18424 (observations 115155-115200/829080) loss: 4.134375\n",
      "2025-02-28 11:55:33 | Batch 2570/18424 (observations 115605-115650/829080) loss: 4.109375\n",
      "2025-02-28 11:55:51 | Batch 2580/18424 (observations 116055-116100/829080) loss: 4.1375\n",
      "2025-02-28 11:56:10 | Batch 2590/18424 (observations 116505-116550/829080) loss: 4.078125\n",
      "2025-02-28 11:56:28 | Batch 2600/18424 (observations 116955-117000/829080) loss: 4.1484375\n",
      "2025-02-28 11:56:46 | Batch 2610/18424 (observations 117405-117450/829080) loss: 4.03125\n",
      "2025-02-28 11:57:05 | Batch 2620/18424 (observations 117855-117900/829080) loss: 4.1203125\n",
      "2025-02-28 11:57:23 | Batch 2630/18424 (observations 118305-118350/829080) loss: 4.1171875\n",
      "2025-02-28 11:57:42 | Batch 2640/18424 (observations 118755-118800/829080) loss: 4.1375\n",
      "2025-02-28 11:58:00 | Batch 2650/18424 (observations 119205-119250/829080) loss: 4.0765625\n",
      "2025-02-28 11:58:19 | Batch 2660/18424 (observations 119655-119700/829080) loss: 4.1140625\n",
      "2025-02-28 11:58:37 | Batch 2670/18424 (observations 120105-120150/829080) loss: 4.1671875\n",
      "2025-02-28 11:58:56 | Batch 2680/18424 (observations 120555-120600/829080) loss: 4.115625\n",
      "2025-02-28 11:59:14 | Batch 2690/18424 (observations 121005-121050/829080) loss: 4.128125\n",
      "2025-02-28 11:59:32 | Batch 2700/18424 (observations 121455-121500/829080) loss: 4.190625\n",
      "2025-02-28 11:59:51 | Batch 2710/18424 (observations 121905-121950/829080) loss: 4.159375\n",
      "2025-02-28 12:00:09 | Batch 2720/18424 (observations 122355-122400/829080) loss: 4.0875\n",
      "2025-02-28 12:00:28 | Batch 2730/18424 (observations 122805-122850/829080) loss: 4.0859375\n",
      "2025-02-28 12:00:46 | Batch 2740/18424 (observations 123255-123300/829080) loss: 4.0875\n",
      "2025-02-28 12:01:04 | Batch 2750/18424 (observations 123705-123750/829080) loss: 4.134375\n",
      "2025-02-28 12:01:23 | Batch 2760/18424 (observations 124155-124200/829080) loss: 4.1375\n",
      "2025-02-28 12:01:41 | Batch 2770/18424 (observations 124605-124650/829080) loss: 4.0203125\n",
      "2025-02-28 12:02:00 | Batch 2780/18424 (observations 125055-125100/829080) loss: 4.1625\n",
      "2025-02-28 12:02:18 | Batch 2790/18424 (observations 125505-125550/829080) loss: 4.0921875\n",
      "2025-02-28 12:02:37 | Batch 2800/18424 (observations 125955-126000/829080) loss: 4.15\n",
      "2025-02-28 12:02:55 | Batch 2810/18424 (observations 126405-126450/829080) loss: 4.0484375\n",
      "2025-02-28 12:03:13 | Batch 2820/18424 (observations 126855-126900/829080) loss: 4.103125\n",
      "2025-02-28 12:03:32 | Batch 2830/18424 (observations 127305-127350/829080) loss: 4.1171875\n",
      "2025-02-28 12:03:50 | Batch 2840/18424 (observations 127755-127800/829080) loss: 4.153125\n",
      "2025-02-28 12:04:09 | Batch 2850/18424 (observations 128205-128250/829080) loss: 4.1390625\n",
      "2025-02-28 12:04:27 | Batch 2860/18424 (observations 128655-128700/829080) loss: 4.103125\n",
      "2025-02-28 12:04:46 | Batch 2870/18424 (observations 129105-129150/829080) loss: 4.14375\n",
      "2025-02-28 12:05:04 | Batch 2880/18424 (observations 129555-129600/829080) loss: 4.165625\n",
      "2025-02-28 12:05:22 | Batch 2890/18424 (observations 130005-130050/829080) loss: 4.078125\n",
      "2025-02-28 12:05:41 | Batch 2900/18424 (observations 130455-130500/829080) loss: 4.10625\n",
      "2025-02-28 12:05:59 | Batch 2910/18424 (observations 130905-130950/829080) loss: 4.04375\n",
      "2025-02-28 12:06:18 | Batch 2920/18424 (observations 131355-131400/829080) loss: 4.1234375\n",
      "2025-02-28 12:06:36 | Batch 2930/18424 (observations 131805-131850/829080) loss: 4.0671875\n",
      "2025-02-28 12:06:55 | Batch 2940/18424 (observations 132255-132300/829080) loss: 4.128125\n",
      "2025-02-28 12:07:13 | Batch 2950/18424 (observations 132705-132750/829080) loss: 4.1\n",
      "2025-02-28 12:07:31 | Batch 2960/18424 (observations 133155-133200/829080) loss: 4.0859375\n",
      "2025-02-28 12:07:50 | Batch 2970/18424 (observations 133605-133650/829080) loss: 4.16875\n",
      "2025-02-28 12:08:08 | Batch 2980/18424 (observations 134055-134100/829080) loss: 4.1515625\n",
      "2025-02-28 12:08:27 | Batch 2990/18424 (observations 134505-134550/829080) loss: 4.096875\n",
      "2025-02-28 12:08:45 | Batch 3000/18424 (observations 134955-135000/829080) loss: 4.1203125\n",
      "2025-02-28 12:09:03 | Batch 3010/18424 (observations 135405-135450/829080) loss: 4.0828125\n",
      "2025-02-28 12:09:22 | Batch 3020/18424 (observations 135855-135900/829080) loss: 4.14375\n",
      "2025-02-28 12:09:40 | Batch 3030/18424 (observations 136305-136350/829080) loss: 4.165625\n",
      "2025-02-28 12:09:59 | Batch 3040/18424 (observations 136755-136800/829080) loss: 4.103125\n",
      "2025-02-28 12:10:17 | Batch 3050/18424 (observations 137205-137250/829080) loss: 4.140625\n",
      "2025-02-28 12:10:36 | Batch 3060/18424 (observations 137655-137700/829080) loss: 4.1390625\n",
      "2025-02-28 12:10:54 | Batch 3070/18424 (observations 138105-138150/829080) loss: 4.196875\n",
      "2025-02-28 12:11:13 | Batch 3080/18424 (observations 138555-138600/829080) loss: 4.1078125\n",
      "2025-02-28 12:11:31 | Batch 3090/18424 (observations 139005-139050/829080) loss: 4.1046875\n",
      "2025-02-28 12:11:49 | Batch 3100/18424 (observations 139455-139500/829080) loss: 4.13125\n",
      "2025-02-28 12:12:08 | Batch 3110/18424 (observations 139905-139950/829080) loss: 4.071875\n",
      "2025-02-28 12:12:26 | Batch 3120/18424 (observations 140355-140400/829080) loss: 4.1015625\n",
      "2025-02-28 12:12:45 | Batch 3130/18424 (observations 140805-140850/829080) loss: 4.1046875\n",
      "2025-02-28 12:13:03 | Batch 3140/18424 (observations 141255-141300/829080) loss: 4.11875\n",
      "2025-02-28 12:13:21 | Batch 3150/18424 (observations 141705-141750/829080) loss: 4.0921875\n",
      "2025-02-28 12:13:40 | Batch 3160/18424 (observations 142155-142200/829080) loss: 4.184375\n",
      "2025-02-28 12:13:58 | Batch 3170/18424 (observations 142605-142650/829080) loss: 4.075\n",
      "2025-02-28 12:14:17 | Batch 3180/18424 (observations 143055-143100/829080) loss: 4.065625\n",
      "2025-02-28 12:14:35 | Batch 3190/18424 (observations 143505-143550/829080) loss: 4.20625\n",
      "2025-02-28 12:14:54 | Batch 3200/18424 (observations 143955-144000/829080) loss: 4.128125\n",
      "2025-02-28 12:15:12 | Batch 3210/18424 (observations 144405-144450/829080) loss: 4.171875\n",
      "2025-02-28 12:15:31 | Batch 3220/18424 (observations 144855-144900/829080) loss: 4.1765625\n",
      "2025-02-28 12:15:49 | Batch 3230/18424 (observations 145305-145350/829080) loss: 4.128125\n",
      "2025-02-28 12:16:07 | Batch 3240/18424 (observations 145755-145800/829080) loss: 4.1453125\n",
      "2025-02-28 12:16:26 | Batch 3250/18424 (observations 146205-146250/829080) loss: 4.1453125\n",
      "2025-02-28 12:16:44 | Batch 3260/18424 (observations 146655-146700/829080) loss: 4.175\n",
      "2025-02-28 12:17:03 | Batch 3270/18424 (observations 147105-147150/829080) loss: 4.1859375\n",
      "2025-02-28 12:17:21 | Batch 3280/18424 (observations 147555-147600/829080) loss: 4.0953125\n",
      "2025-02-28 12:17:39 | Batch 3290/18424 (observations 148005-148050/829080) loss: 4.16875\n",
      "2025-02-28 12:17:58 | Batch 3300/18424 (observations 148455-148500/829080) loss: 4.178125\n",
      "2025-02-28 12:18:17 | Batch 3310/18424 (observations 148905-148950/829080) loss: 4.175\n",
      "2025-02-28 12:18:36 | Batch 3320/18424 (observations 149355-149400/829080) loss: 4.1828125\n",
      "2025-02-28 12:18:55 | Batch 3330/18424 (observations 149805-149850/829080) loss: 4.1515625\n",
      "2025-02-28 12:19:14 | Batch 3340/18424 (observations 150255-150300/829080) loss: 4.1234375\n",
      "2025-02-28 12:19:33 | Batch 3350/18424 (observations 150705-150750/829080) loss: 4.153125\n",
      "2025-02-28 12:19:51 | Batch 3360/18424 (observations 151155-151200/829080) loss: 4.1671875\n",
      "2025-02-28 12:20:10 | Batch 3370/18424 (observations 151605-151650/829080) loss: 4.0734375\n",
      "2025-02-28 12:20:29 | Batch 3380/18424 (observations 152055-152100/829080) loss: 4.128125\n",
      "2025-02-28 12:20:47 | Batch 3390/18424 (observations 152505-152550/829080) loss: 4.1109375\n",
      "2025-02-28 12:21:06 | Batch 3400/18424 (observations 152955-153000/829080) loss: 4.2125\n",
      "2025-02-28 12:21:25 | Batch 3410/18424 (observations 153405-153450/829080) loss: 4.1015625\n",
      "2025-02-28 12:21:43 | Batch 3420/18424 (observations 153855-153900/829080) loss: 4.0984375\n",
      "2025-02-28 12:22:02 | Batch 3430/18424 (observations 154305-154350/829080) loss: 4.125\n",
      "2025-02-28 12:22:20 | Batch 3440/18424 (observations 154755-154800/829080) loss: 4.146875\n",
      "2025-02-28 12:22:39 | Batch 3450/18424 (observations 155205-155250/829080) loss: 4.1625\n",
      "2025-02-28 12:22:57 | Batch 3460/18424 (observations 155655-155700/829080) loss: 4.146875\n",
      "2025-02-28 12:23:16 | Batch 3470/18424 (observations 156105-156150/829080) loss: 4.1046875\n",
      "2025-02-28 12:23:34 | Batch 3480/18424 (observations 156555-156600/829080) loss: 4.1328125\n",
      "2025-02-28 12:23:53 | Batch 3490/18424 (observations 157005-157050/829080) loss: 4.165625\n",
      "2025-02-28 12:24:11 | Batch 3500/18424 (observations 157455-157500/829080) loss: 4.0984375\n",
      "2025-02-28 12:24:30 | Batch 3510/18424 (observations 157905-157950/829080) loss: 4.084375\n",
      "2025-02-28 12:24:48 | Batch 3520/18424 (observations 158355-158400/829080) loss: 4.1375\n",
      "2025-02-28 12:25:07 | Batch 3530/18424 (observations 158805-158850/829080) loss: 4.1625\n",
      "2025-02-28 12:25:25 | Batch 3540/18424 (observations 159255-159300/829080) loss: 4.115625\n",
      "2025-02-28 12:25:44 | Batch 3550/18424 (observations 159705-159750/829080) loss: 4.184375\n",
      "2025-02-28 12:26:03 | Batch 3560/18424 (observations 160155-160200/829080) loss: 4.178125\n",
      "2025-02-28 12:26:21 | Batch 3570/18424 (observations 160605-160650/829080) loss: 4.1125\n",
      "2025-02-28 12:26:40 | Batch 3580/18424 (observations 161055-161100/829080) loss: 4.1625\n",
      "2025-02-28 12:26:58 | Batch 3590/18424 (observations 161505-161550/829080) loss: 4.1078125\n",
      "2025-02-28 12:27:17 | Batch 3600/18424 (observations 161955-162000/829080) loss: 4.08125\n",
      "2025-02-28 12:27:35 | Batch 3610/18424 (observations 162405-162450/829080) loss: 4.078125\n",
      "2025-02-28 12:27:54 | Batch 3620/18424 (observations 162855-162900/829080) loss: 4.0859375\n",
      "2025-02-28 12:28:12 | Batch 3630/18424 (observations 163305-163350/829080) loss: 4.10625\n",
      "2025-02-28 12:28:31 | Batch 3640/18424 (observations 163755-163800/829080) loss: 4.0828125\n",
      "2025-02-28 12:28:49 | Batch 3650/18424 (observations 164205-164250/829080) loss: 4.08125\n",
      "2025-02-28 12:29:08 | Batch 3660/18424 (observations 164655-164700/829080) loss: 4.1453125\n",
      "2025-02-28 12:29:26 | Batch 3670/18424 (observations 165105-165150/829080) loss: 4.1109375\n",
      "2025-02-28 12:29:45 | Batch 3680/18424 (observations 165555-165600/829080) loss: 4.15625\n",
      "2025-02-28 12:30:03 | Batch 3690/18424 (observations 166005-166050/829080) loss: 4.1078125\n",
      "2025-02-28 12:30:22 | Batch 3700/18424 (observations 166455-166500/829080) loss: 4.078125\n",
      "2025-02-28 12:30:40 | Batch 3710/18424 (observations 166905-166950/829080) loss: 4.153125\n",
      "2025-02-28 12:30:59 | Batch 3720/18424 (observations 167355-167400/829080) loss: 4.11875\n",
      "2025-02-28 12:31:17 | Batch 3730/18424 (observations 167805-167850/829080) loss: 4.1484375\n",
      "2025-02-28 12:31:35 | Batch 3740/18424 (observations 168255-168300/829080) loss: 4.121875\n",
      "2025-02-28 12:31:54 | Batch 3750/18424 (observations 168705-168750/829080) loss: 4.14375\n",
      "2025-02-28 12:32:12 | Batch 3760/18424 (observations 169155-169200/829080) loss: 4.1078125\n",
      "2025-02-28 12:32:31 | Batch 3770/18424 (observations 169605-169650/829080) loss: 4.084375\n",
      "2025-02-28 12:32:49 | Batch 3780/18424 (observations 170055-170100/829080) loss: 4.1234375\n",
      "2025-02-28 12:33:07 | Batch 3790/18424 (observations 170505-170550/829080) loss: 4.0765625\n",
      "2025-02-28 12:33:26 | Batch 3800/18424 (observations 170955-171000/829080) loss: 4.125\n",
      "2025-02-28 12:33:44 | Batch 3810/18424 (observations 171405-171450/829080) loss: 4.0875\n",
      "2025-02-28 12:34:03 | Batch 3820/18424 (observations 171855-171900/829080) loss: 4.0328125\n",
      "2025-02-28 12:34:21 | Batch 3830/18424 (observations 172305-172350/829080) loss: 4.109375\n",
      "2025-02-28 12:34:40 | Batch 3840/18424 (observations 172755-172800/829080) loss: 4.1171875\n",
      "2025-02-28 12:34:58 | Batch 3850/18424 (observations 173205-173250/829080) loss: 4.15\n",
      "2025-02-28 12:35:17 | Batch 3860/18424 (observations 173655-173700/829080) loss: 4.115625\n",
      "2025-02-28 12:35:35 | Batch 3870/18424 (observations 174105-174150/829080) loss: 4.1140625\n",
      "2025-02-28 12:35:53 | Batch 3880/18424 (observations 174555-174600/829080) loss: 4.15625\n",
      "2025-02-28 12:36:12 | Batch 3890/18424 (observations 175005-175050/829080) loss: 4.053125\n",
      "2025-02-28 12:36:30 | Batch 3900/18424 (observations 175455-175500/829080) loss: 4.0890625\n",
      "2025-02-28 12:36:49 | Batch 3910/18424 (observations 175905-175950/829080) loss: 4.109375\n",
      "2025-02-28 12:37:07 | Batch 3920/18424 (observations 176355-176400/829080) loss: 4.115625\n",
      "2025-02-28 12:37:25 | Batch 3930/18424 (observations 176805-176850/829080) loss: 4.2\n",
      "2025-02-28 12:37:44 | Batch 3940/18424 (observations 177255-177300/829080) loss: 4.175\n",
      "2025-02-28 12:38:02 | Batch 3950/18424 (observations 177705-177750/829080) loss: 4.1515625\n",
      "2025-02-28 12:38:21 | Batch 3960/18424 (observations 178155-178200/829080) loss: 4.096875\n",
      "2025-02-28 12:38:39 | Batch 3970/18424 (observations 178605-178650/829080) loss: 4.171875\n",
      "2025-02-28 12:38:58 | Batch 3980/18424 (observations 179055-179100/829080) loss: 4.1265625\n",
      "2025-02-28 12:39:16 | Batch 3990/18424 (observations 179505-179550/829080) loss: 4.096875\n",
      "2025-02-28 12:39:35 | Batch 4000/18424 (observations 179955-180000/829080) loss: 4.1109375\n",
      "2025-02-28 12:39:53 | Batch 4010/18424 (observations 180405-180450/829080) loss: 4.1234375\n",
      "2025-02-28 12:40:11 | Batch 4020/18424 (observations 180855-180900/829080) loss: 4.0953125\n",
      "2025-02-28 12:40:30 | Batch 4030/18424 (observations 181305-181350/829080) loss: 4.1390625\n",
      "2025-02-28 12:40:48 | Batch 4040/18424 (observations 181755-181800/829080) loss: 4.1453125\n",
      "2025-02-28 12:41:07 | Batch 4050/18424 (observations 182205-182250/829080) loss: 4.0328125\n",
      "2025-02-28 12:41:25 | Batch 4060/18424 (observations 182655-182700/829080) loss: 4.15625\n",
      "2025-02-28 12:41:43 | Batch 4070/18424 (observations 183105-183150/829080) loss: 4.1109375\n",
      "2025-02-28 12:42:02 | Batch 4080/18424 (observations 183555-183600/829080) loss: 4.0796875\n",
      "2025-02-28 12:42:20 | Batch 4090/18424 (observations 184005-184050/829080) loss: 4.10625\n",
      "2025-02-28 12:42:39 | Batch 4100/18424 (observations 184455-184500/829080) loss: 4.0296875\n",
      "2025-02-28 12:42:57 | Batch 4110/18424 (observations 184905-184950/829080) loss: 4.1703125\n",
      "2025-02-28 12:43:16 | Batch 4120/18424 (observations 185355-185400/829080) loss: 4.1453125\n",
      "2025-02-28 12:43:34 | Batch 4130/18424 (observations 185805-185850/829080) loss: 4.059375\n",
      "2025-02-28 12:43:53 | Batch 4140/18424 (observations 186255-186300/829080) loss: 4.14375\n",
      "2025-02-28 12:44:11 | Batch 4150/18424 (observations 186705-186750/829080) loss: 4.10625\n",
      "2025-02-28 12:44:29 | Batch 4160/18424 (observations 187155-187200/829080) loss: 4.096875\n",
      "2025-02-28 12:44:48 | Batch 4170/18424 (observations 187605-187650/829080) loss: 4.1078125\n",
      "2025-02-28 12:45:06 | Batch 4180/18424 (observations 188055-188100/829080) loss: 4.1609375\n",
      "2025-02-28 12:45:25 | Batch 4190/18424 (observations 188505-188550/829080) loss: 4.125\n",
      "2025-02-28 12:45:43 | Batch 4200/18424 (observations 188955-189000/829080) loss: 4.125\n",
      "2025-02-28 12:46:02 | Batch 4210/18424 (observations 189405-189450/829080) loss: 4.115625\n",
      "2025-02-28 12:46:20 | Batch 4220/18424 (observations 189855-189900/829080) loss: 4.2\n",
      "2025-02-28 12:46:38 | Batch 4230/18424 (observations 190305-190350/829080) loss: 4.14375\n",
      "2025-02-28 12:46:57 | Batch 4240/18424 (observations 190755-190800/829080) loss: 4.1390625\n",
      "2025-02-28 12:47:15 | Batch 4250/18424 (observations 191205-191250/829080) loss: 4.0953125\n",
      "2025-02-28 12:47:34 | Batch 4260/18424 (observations 191655-191700/829080) loss: 4.115625\n",
      "2025-02-28 12:47:52 | Batch 4270/18424 (observations 192105-192150/829080) loss: 4.0953125\n",
      "2025-02-28 12:48:11 | Batch 4280/18424 (observations 192555-192600/829080) loss: 4.159375\n",
      "2025-02-28 12:48:29 | Batch 4290/18424 (observations 193005-193050/829080) loss: 4.103125\n",
      "2025-02-28 12:48:48 | Batch 4300/18424 (observations 193455-193500/829080) loss: 4.1203125\n",
      "2025-02-28 12:49:06 | Batch 4310/18424 (observations 193905-193950/829080) loss: 4.16875\n",
      "2025-02-28 12:49:25 | Batch 4320/18424 (observations 194355-194400/829080) loss: 4.1515625\n",
      "2025-02-28 12:49:44 | Batch 4330/18424 (observations 194805-194850/829080) loss: 4.115625\n",
      "2025-02-28 12:50:02 | Batch 4340/18424 (observations 195255-195300/829080) loss: 4.184375\n",
      "2025-02-28 12:50:21 | Batch 4350/18424 (observations 195705-195750/829080) loss: 4.109375\n",
      "2025-02-28 12:50:39 | Batch 4360/18424 (observations 196155-196200/829080) loss: 4.165625\n",
      "2025-02-28 12:50:58 | Batch 4370/18424 (observations 196605-196650/829080) loss: 4.1265625\n",
      "2025-02-28 12:51:16 | Batch 4380/18424 (observations 197055-197100/829080) loss: 4.1515625\n",
      "2025-02-28 12:51:35 | Batch 4390/18424 (observations 197505-197550/829080) loss: 4.16875\n",
      "2025-02-28 12:51:54 | Batch 4400/18424 (observations 197955-198000/829080) loss: 4.146875\n",
      "2025-02-28 12:52:12 | Batch 4410/18424 (observations 198405-198450/829080) loss: 4.1265625\n",
      "2025-02-28 12:52:31 | Batch 4420/18424 (observations 198855-198900/829080) loss: 4.121875\n",
      "2025-02-28 12:52:49 | Batch 4430/18424 (observations 199305-199350/829080) loss: 4.1140625\n",
      "2025-02-28 12:53:08 | Batch 4440/18424 (observations 199755-199800/829080) loss: 4.0953125\n",
      "2025-02-28 12:53:26 | Batch 4450/18424 (observations 200205-200250/829080) loss: 4.159375\n",
      "2025-02-28 12:53:45 | Batch 4460/18424 (observations 200655-200700/829080) loss: 4.125\n",
      "2025-02-28 12:54:04 | Batch 4470/18424 (observations 201105-201150/829080) loss: 4.0953125\n",
      "2025-02-28 12:54:22 | Batch 4480/18424 (observations 201555-201600/829080) loss: 4.134375\n",
      "2025-02-28 12:54:41 | Batch 4490/18424 (observations 202005-202050/829080) loss: 4.1359375\n",
      "2025-02-28 12:54:59 | Batch 4500/18424 (observations 202455-202500/829080) loss: 4.1296875\n",
      "2025-02-28 12:55:18 | Batch 4510/18424 (observations 202905-202950/829080) loss: 4.1078125\n",
      "2025-02-28 12:55:37 | Batch 4520/18424 (observations 203355-203400/829080) loss: 4.1140625\n",
      "2025-02-28 12:55:55 | Batch 4530/18424 (observations 203805-203850/829080) loss: 4.1390625\n",
      "2025-02-28 12:56:14 | Batch 4540/18424 (observations 204255-204300/829080) loss: 4.159375\n",
      "2025-02-28 12:56:32 | Batch 4550/18424 (observations 204705-204750/829080) loss: 4.0796875\n",
      "2025-02-28 12:56:51 | Batch 4560/18424 (observations 205155-205200/829080) loss: 4.078125\n",
      "2025-02-28 12:57:10 | Batch 4570/18424 (observations 205605-205650/829080) loss: 4.1296875\n",
      "2025-02-28 12:57:28 | Batch 4580/18424 (observations 206055-206100/829080) loss: 4.1625\n",
      "2025-02-28 12:57:46 | Batch 4590/18424 (observations 206505-206550/829080) loss: 4.14375\n",
      "2025-02-28 12:58:05 | Batch 4600/18424 (observations 206955-207000/829080) loss: 4.1140625\n",
      "2025-02-28 12:58:23 | Batch 4610/18424 (observations 207405-207450/829080) loss: 4.04375\n",
      "2025-02-28 12:58:42 | Batch 4620/18424 (observations 207855-207900/829080) loss: 4.1046875\n",
      "2025-02-28 12:59:00 | Batch 4630/18424 (observations 208305-208350/829080) loss: 4.14375\n",
      "2025-02-28 12:59:18 | Batch 4640/18424 (observations 208755-208800/829080) loss: 4.096875\n",
      "2025-02-28 12:59:37 | Batch 4650/18424 (observations 209205-209250/829080) loss: 4.0734375\n",
      "2025-02-28 12:59:55 | Batch 4660/18424 (observations 209655-209700/829080) loss: 4.0609375\n",
      "2025-02-28 13:00:14 | Batch 4670/18424 (observations 210105-210150/829080) loss: 4.0515625\n",
      "2025-02-28 13:00:32 | Batch 4680/18424 (observations 210555-210600/829080) loss: 4.0796875\n",
      "2025-02-28 13:00:51 | Batch 4690/18424 (observations 211005-211050/829080) loss: 4.1171875\n",
      "2025-02-28 13:01:09 | Batch 4700/18424 (observations 211455-211500/829080) loss: 4.11875\n",
      "2025-02-28 13:01:28 | Batch 4710/18424 (observations 211905-211950/829080) loss: 4.065625\n",
      "2025-02-28 13:01:46 | Batch 4720/18424 (observations 212355-212400/829080) loss: 4.1015625\n",
      "2025-02-28 13:02:04 | Batch 4730/18424 (observations 212805-212850/829080) loss: 4.1015625\n",
      "2025-02-28 13:02:23 | Batch 4740/18424 (observations 213255-213300/829080) loss: 4.1234375\n",
      "2025-02-28 13:02:41 | Batch 4750/18424 (observations 213705-213750/829080) loss: 4.08125\n",
      "2025-02-28 13:03:00 | Batch 4760/18424 (observations 214155-214200/829080) loss: 4.109375\n",
      "2025-02-28 13:03:18 | Batch 4770/18424 (observations 214605-214650/829080) loss: 4.175\n",
      "2025-02-28 13:03:37 | Batch 4780/18424 (observations 215055-215100/829080) loss: 4.09375\n",
      "2025-02-28 13:03:55 | Batch 4790/18424 (observations 215505-215550/829080) loss: 4.1078125\n",
      "2025-02-28 13:04:13 | Batch 4800/18424 (observations 215955-216000/829080) loss: 4.1265625\n",
      "2025-02-28 13:04:32 | Batch 4810/18424 (observations 216405-216450/829080) loss: 4.0984375\n",
      "2025-02-28 13:04:50 | Batch 4820/18424 (observations 216855-216900/829080) loss: 4.14375\n",
      "2025-02-28 13:05:09 | Batch 4830/18424 (observations 217305-217350/829080) loss: 4.0859375\n",
      "2025-02-28 13:05:27 | Batch 4840/18424 (observations 217755-217800/829080) loss: 4.0703125\n",
      "2025-02-28 13:05:46 | Batch 4850/18424 (observations 218205-218250/829080) loss: 4.13125\n",
      "2025-02-28 13:06:04 | Batch 4860/18424 (observations 218655-218700/829080) loss: 4.1390625\n",
      "2025-02-28 13:06:22 | Batch 4870/18424 (observations 219105-219150/829080) loss: 4.0859375\n",
      "2025-02-28 13:06:41 | Batch 4880/18424 (observations 219555-219600/829080) loss: 4.153125\n",
      "2025-02-28 13:06:59 | Batch 4890/18424 (observations 220005-220050/829080) loss: 4.0765625\n",
      "2025-02-28 13:07:18 | Batch 4900/18424 (observations 220455-220500/829080) loss: 4.10625\n",
      "2025-02-28 13:07:36 | Batch 4910/18424 (observations 220905-220950/829080) loss: 4.13125\n",
      "2025-02-28 13:07:55 | Batch 4920/18424 (observations 221355-221400/829080) loss: 4.0875\n",
      "2025-02-28 13:08:13 | Batch 4930/18424 (observations 221805-221850/829080) loss: 4.06875\n",
      "2025-02-28 13:08:32 | Batch 4940/18424 (observations 222255-222300/829080) loss: 4.090625\n",
      "2025-02-28 13:08:50 | Batch 4950/18424 (observations 222705-222750/829080) loss: 4.134375\n",
      "2025-02-28 13:09:09 | Batch 4960/18424 (observations 223155-223200/829080) loss: 4.0703125\n",
      "2025-02-28 13:09:27 | Batch 4970/18424 (observations 223605-223650/829080) loss: 4.109375\n",
      "2025-02-28 13:09:46 | Batch 4980/18424 (observations 224055-224100/829080) loss: 4.1453125\n",
      "2025-02-28 13:10:05 | Batch 4990/18424 (observations 224505-224550/829080) loss: 4.09375\n",
      "2025-02-28 13:10:23 | Batch 5000/18424 (observations 224955-225000/829080) loss: 4.0875\n",
      "2025-02-28 13:10:42 | Batch 5010/18424 (observations 225405-225450/829080) loss: 4.1234375\n",
      "2025-02-28 13:11:00 | Batch 5020/18424 (observations 225855-225900/829080) loss: 4.1015625\n",
      "2025-02-28 13:11:19 | Batch 5030/18424 (observations 226305-226350/829080) loss: 4.084375\n",
      "2025-02-28 13:11:38 | Batch 5040/18424 (observations 226755-226800/829080) loss: 4.0921875\n",
      "2025-02-28 13:11:56 | Batch 5050/18424 (observations 227205-227250/829080) loss: 4.13125\n",
      "2025-02-28 13:12:15 | Batch 5060/18424 (observations 227655-227700/829080) loss: 4.0546875\n",
      "2025-02-28 13:12:33 | Batch 5070/18424 (observations 228105-228150/829080) loss: 4.0828125\n",
      "2025-02-28 13:12:52 | Batch 5080/18424 (observations 228555-228600/829080) loss: 4.08125\n",
      "2025-02-28 13:13:10 | Batch 5090/18424 (observations 229005-229050/829080) loss: 4.165625\n",
      "2025-02-28 13:13:29 | Batch 5100/18424 (observations 229455-229500/829080) loss: 4.0984375\n",
      "2025-02-28 13:13:47 | Batch 5110/18424 (observations 229905-229950/829080) loss: 4.1046875\n",
      "2025-02-28 13:14:05 | Batch 5120/18424 (observations 230355-230400/829080) loss: 4.1203125\n",
      "2025-02-28 13:14:24 | Batch 5130/18424 (observations 230805-230850/829080) loss: 4.134375\n",
      "2025-02-28 13:14:42 | Batch 5140/18424 (observations 231255-231300/829080) loss: 4.175\n",
      "2025-02-28 13:15:01 | Batch 5150/18424 (observations 231705-231750/829080) loss: 4.209375\n",
      "2025-02-28 13:15:19 | Batch 5160/18424 (observations 232155-232200/829080) loss: 4.0859375\n",
      "2025-02-28 13:15:37 | Batch 5170/18424 (observations 232605-232650/829080) loss: 4.0890625\n",
      "2025-02-28 13:15:56 | Batch 5180/18424 (observations 233055-233100/829080) loss: 4.103125\n",
      "2025-02-28 13:16:14 | Batch 5190/18424 (observations 233505-233550/829080) loss: 4.115625\n",
      "2025-02-28 13:16:33 | Batch 5200/18424 (observations 233955-234000/829080) loss: 4.1421875\n",
      "2025-02-28 13:16:51 | Batch 5210/18424 (observations 234405-234450/829080) loss: 4.0890625\n",
      "2025-02-28 13:17:10 | Batch 5220/18424 (observations 234855-234900/829080) loss: 4.1\n",
      "2025-02-28 13:17:28 | Batch 5230/18424 (observations 235305-235350/829080) loss: 4.1421875\n",
      "2025-02-28 13:17:47 | Batch 5240/18424 (observations 235755-235800/829080) loss: 4.153125\n",
      "2025-02-28 13:18:05 | Batch 5250/18424 (observations 236205-236250/829080) loss: 4.15\n",
      "2025-02-28 13:18:24 | Batch 5260/18424 (observations 236655-236700/829080) loss: 4.1078125\n",
      "2025-02-28 13:18:42 | Batch 5270/18424 (observations 237105-237150/829080) loss: 4.096875\n",
      "2025-02-28 13:19:01 | Batch 5280/18424 (observations 237555-237600/829080) loss: 4.153125\n",
      "2025-02-28 13:19:19 | Batch 5290/18424 (observations 238005-238050/829080) loss: 4.1453125\n",
      "2025-02-28 13:19:38 | Batch 5300/18424 (observations 238455-238500/829080) loss: 4.1140625\n",
      "2025-02-28 13:19:56 | Batch 5310/18424 (observations 238905-238950/829080) loss: 4.0984375\n",
      "2025-02-28 13:20:15 | Batch 5320/18424 (observations 239355-239400/829080) loss: 4.153125\n",
      "2025-02-28 13:20:33 | Batch 5330/18424 (observations 239805-239850/829080) loss: 4.0875\n",
      "2025-02-28 13:20:52 | Batch 5340/18424 (observations 240255-240300/829080) loss: 4.153125\n",
      "2025-02-28 13:21:10 | Batch 5350/18424 (observations 240705-240750/829080) loss: 4.078125\n",
      "2025-02-28 13:21:28 | Batch 5360/18424 (observations 241155-241200/829080) loss: 4.0359375\n",
      "2025-02-28 13:21:47 | Batch 5370/18424 (observations 241605-241650/829080) loss: 4.1453125\n",
      "2025-02-28 13:22:05 | Batch 5380/18424 (observations 242055-242100/829080) loss: 4.134375\n",
      "2025-02-28 13:22:24 | Batch 5390/18424 (observations 242505-242550/829080) loss: 4.1046875\n",
      "2025-02-28 13:22:42 | Batch 5400/18424 (observations 242955-243000/829080) loss: 4.1390625\n",
      "2025-02-28 13:23:01 | Batch 5410/18424 (observations 243405-243450/829080) loss: 4.165625\n",
      "2025-02-28 13:23:19 | Batch 5420/18424 (observations 243855-243900/829080) loss: 4.159375\n",
      "2025-02-28 13:23:38 | Batch 5430/18424 (observations 244305-244350/829080) loss: 4.10625\n",
      "2025-02-28 13:23:56 | Batch 5440/18424 (observations 244755-244800/829080) loss: 4.1109375\n",
      "2025-02-28 13:24:15 | Batch 5450/18424 (observations 245205-245250/829080) loss: 4.125\n",
      "2025-02-28 13:24:34 | Batch 5460/18424 (observations 245655-245700/829080) loss: 4.171875\n",
      "2025-02-28 13:24:52 | Batch 5470/18424 (observations 246105-246150/829080) loss: 4.065625\n",
      "2025-02-28 13:25:11 | Batch 5480/18424 (observations 246555-246600/829080) loss: 4.128125\n",
      "2025-02-28 13:25:29 | Batch 5490/18424 (observations 247005-247050/829080) loss: 4.18125\n",
      "2025-02-28 13:25:48 | Batch 5500/18424 (observations 247455-247500/829080) loss: 4.06875\n",
      "2025-02-28 13:26:07 | Batch 5510/18424 (observations 247905-247950/829080) loss: 4.10625\n",
      "2025-02-28 13:26:25 | Batch 5520/18424 (observations 248355-248400/829080) loss: 4.14375\n",
      "2025-02-28 13:26:44 | Batch 5530/18424 (observations 248805-248850/829080) loss: 4.134375\n",
      "2025-02-28 13:27:02 | Batch 5540/18424 (observations 249255-249300/829080) loss: 4.0734375\n",
      "2025-02-28 13:27:21 | Batch 5550/18424 (observations 249705-249750/829080) loss: 4.065625\n",
      "2025-02-28 13:27:39 | Batch 5560/18424 (observations 250155-250200/829080) loss: 4.1234375\n",
      "2025-02-28 13:27:58 | Batch 5570/18424 (observations 250605-250650/829080) loss: 4.115625\n",
      "2025-02-28 13:28:16 | Batch 5580/18424 (observations 251055-251100/829080) loss: 4.203125\n",
      "2025-02-28 13:28:35 | Batch 5590/18424 (observations 251505-251550/829080) loss: 4.1875\n",
      "2025-02-28 13:28:53 | Batch 5600/18424 (observations 251955-252000/829080) loss: 4.075\n",
      "2025-02-28 13:29:11 | Batch 5610/18424 (observations 252405-252450/829080) loss: 4.1546875\n",
      "2025-02-28 13:29:30 | Batch 5620/18424 (observations 252855-252900/829080) loss: 4.1078125\n",
      "2025-02-28 13:29:48 | Batch 5630/18424 (observations 253305-253350/829080) loss: 4.125\n",
      "2025-02-28 13:30:07 | Batch 5640/18424 (observations 253755-253800/829080) loss: 4.1140625\n",
      "2025-02-28 13:30:25 | Batch 5650/18424 (observations 254205-254250/829080) loss: 4.0890625\n",
      "2025-02-28 13:30:44 | Batch 5660/18424 (observations 254655-254700/829080) loss: 4.1078125\n",
      "2025-02-28 13:31:02 | Batch 5670/18424 (observations 255105-255150/829080) loss: 4.134375\n",
      "2025-02-28 13:31:20 | Batch 5680/18424 (observations 255555-255600/829080) loss: 4.11875\n",
      "2025-02-28 13:31:39 | Batch 5690/18424 (observations 256005-256050/829080) loss: 4.140625\n",
      "2025-02-28 13:31:57 | Batch 5700/18424 (observations 256455-256500/829080) loss: 4.090625\n",
      "2025-02-28 13:32:16 | Batch 5710/18424 (observations 256905-256950/829080) loss: 4.1390625\n",
      "2025-02-28 13:32:34 | Batch 5720/18424 (observations 257355-257400/829080) loss: 4.1125\n",
      "2025-02-28 13:32:53 | Batch 5730/18424 (observations 257805-257850/829080) loss: 4.1375\n",
      "2025-02-28 13:33:11 | Batch 5740/18424 (observations 258255-258300/829080) loss: 4.14375\n",
      "2025-02-28 13:33:29 | Batch 5750/18424 (observations 258705-258750/829080) loss: 4.0390625\n",
      "2025-02-28 13:33:48 | Batch 5760/18424 (observations 259155-259200/829080) loss: 4.0515625\n",
      "2025-02-28 13:34:06 | Batch 5770/18424 (observations 259605-259650/829080) loss: 4.0859375\n",
      "2025-02-28 13:34:25 | Batch 5780/18424 (observations 260055-260100/829080) loss: 4.1015625\n",
      "2025-02-28 13:34:43 | Batch 5790/18424 (observations 260505-260550/829080) loss: 4.128125\n",
      "2025-02-28 13:35:02 | Batch 5800/18424 (observations 260955-261000/829080) loss: 4.05625\n",
      "2025-02-28 13:35:20 | Batch 5810/18424 (observations 261405-261450/829080) loss: 4.1234375\n",
      "2025-02-28 13:35:38 | Batch 5820/18424 (observations 261855-261900/829080) loss: 4.134375\n",
      "2025-02-28 13:35:57 | Batch 5830/18424 (observations 262305-262350/829080) loss: 4.090625\n",
      "2025-02-28 13:36:15 | Batch 5840/18424 (observations 262755-262800/829080) loss: 4.1390625\n",
      "2025-02-28 13:36:34 | Batch 5850/18424 (observations 263205-263250/829080) loss: 4.109375\n",
      "2025-02-28 13:36:53 | Batch 5860/18424 (observations 263655-263700/829080) loss: 4.1078125\n",
      "2025-02-28 13:37:11 | Batch 5870/18424 (observations 264105-264150/829080) loss: 4.1390625\n",
      "2025-02-28 13:37:30 | Batch 5880/18424 (observations 264555-264600/829080) loss: 4.1125\n",
      "2025-02-28 13:37:48 | Batch 5890/18424 (observations 265005-265050/829080) loss: 4.0640625\n",
      "2025-02-28 13:38:07 | Batch 5900/18424 (observations 265455-265500/829080) loss: 4.084375\n",
      "2025-02-28 13:38:25 | Batch 5910/18424 (observations 265905-265950/829080) loss: 4.1515625\n",
      "2025-02-28 13:38:44 | Batch 5920/18424 (observations 266355-266400/829080) loss: 4.15\n",
      "2025-02-28 13:39:02 | Batch 5930/18424 (observations 266805-266850/829080) loss: 4.1203125\n",
      "2025-02-28 13:39:21 | Batch 5940/18424 (observations 267255-267300/829080) loss: 4.184375\n",
      "2025-02-28 13:39:40 | Batch 5950/18424 (observations 267705-267750/829080) loss: 4.09375\n",
      "2025-02-28 13:39:58 | Batch 5960/18424 (observations 268155-268200/829080) loss: 4.128125\n",
      "2025-02-28 13:40:17 | Batch 5970/18424 (observations 268605-268650/829080) loss: 4.1265625\n",
      "2025-02-28 13:40:35 | Batch 5980/18424 (observations 269055-269100/829080) loss: 4.134375\n",
      "2025-02-28 13:40:54 | Batch 5990/18424 (observations 269505-269550/829080) loss: 4.1015625\n",
      "2025-02-28 13:41:12 | Batch 6000/18424 (observations 269955-270000/829080) loss: 4.0375\n",
      "2025-02-28 13:41:31 | Batch 6010/18424 (observations 270405-270450/829080) loss: 4.1125\n",
      "2025-02-28 13:41:50 | Batch 6020/18424 (observations 270855-270900/829080) loss: 4.13125\n",
      "2025-02-28 13:42:08 | Batch 6030/18424 (observations 271305-271350/829080) loss: 4.1375\n",
      "2025-02-28 13:42:27 | Batch 6040/18424 (observations 271755-271800/829080) loss: 4.0625\n",
      "2025-02-28 13:42:45 | Batch 6050/18424 (observations 272205-272250/829080) loss: 4.159375\n",
      "2025-02-28 13:43:04 | Batch 6060/18424 (observations 272655-272700/829080) loss: 4.125\n",
      "2025-02-28 13:43:22 | Batch 6070/18424 (observations 273105-273150/829080) loss: 4.0671875\n",
      "2025-02-28 13:43:40 | Batch 6080/18424 (observations 273555-273600/829080) loss: 4.134375\n",
      "2025-02-28 13:43:59 | Batch 6090/18424 (observations 274005-274050/829080) loss: 4.065625\n",
      "2025-02-28 13:44:17 | Batch 6100/18424 (observations 274455-274500/829080) loss: 4.1234375\n",
      "2025-02-28 13:44:36 | Batch 6110/18424 (observations 274905-274950/829080) loss: 4.121875\n",
      "2025-02-28 13:44:54 | Batch 6120/18424 (observations 275355-275400/829080) loss: 4.1484375\n",
      "2025-02-28 13:45:13 | Batch 6130/18424 (observations 275805-275850/829080) loss: 4.1046875\n",
      "2025-02-28 13:45:31 | Batch 6140/18424 (observations 276255-276300/829080) loss: 4.0671875\n",
      "2025-02-28 13:45:50 | Batch 6150/18424 (observations 276705-276750/829080) loss: 4.1234375\n",
      "2025-02-28 13:46:09 | Batch 6160/18424 (observations 277155-277200/829080) loss: 4.1625\n",
      "2025-02-28 13:46:27 | Batch 6170/18424 (observations 277605-277650/829080) loss: 4.0984375\n",
      "2025-02-28 13:46:46 | Batch 6180/18424 (observations 278055-278100/829080) loss: 4.1203125\n",
      "2025-02-28 13:47:04 | Batch 6190/18424 (observations 278505-278550/829080) loss: 4.1234375\n",
      "2025-02-28 13:47:23 | Batch 6200/18424 (observations 278955-279000/829080) loss: 4.1078125\n",
      "2025-02-28 13:47:42 | Batch 6210/18424 (observations 279405-279450/829080) loss: 4.14375\n",
      "2025-02-28 13:48:00 | Batch 6220/18424 (observations 279855-279900/829080) loss: 4.1625\n",
      "2025-02-28 13:48:19 | Batch 6230/18424 (observations 280305-280350/829080) loss: 4.10625\n",
      "2025-02-28 13:48:37 | Batch 6240/18424 (observations 280755-280800/829080) loss: 4.184375\n",
      "2025-02-28 13:48:56 | Batch 6250/18424 (observations 281205-281250/829080) loss: 4.0734375\n",
      "2025-02-28 13:49:14 | Batch 6260/18424 (observations 281655-281700/829080) loss: 4.1453125\n",
      "2025-02-28 13:49:33 | Batch 6270/18424 (observations 282105-282150/829080) loss: 4.13125\n",
      "2025-02-28 13:49:52 | Batch 6280/18424 (observations 282555-282600/829080) loss: 4.1125\n",
      "2025-02-28 13:50:10 | Batch 6290/18424 (observations 283005-283050/829080) loss: 4.109375\n",
      "2025-02-28 13:50:29 | Batch 6300/18424 (observations 283455-283500/829080) loss: 4.10625\n",
      "2025-02-28 13:50:47 | Batch 6310/18424 (observations 283905-283950/829080) loss: 4.1765625\n",
      "2025-02-28 13:51:06 | Batch 6320/18424 (observations 284355-284400/829080) loss: 4.1140625\n",
      "2025-02-28 13:51:25 | Batch 6330/18424 (observations 284805-284850/829080) loss: 4.1390625\n",
      "2025-02-28 13:51:43 | Batch 6340/18424 (observations 285255-285300/829080) loss: 4.103125\n",
      "2025-02-28 13:52:02 | Batch 6350/18424 (observations 285705-285750/829080) loss: 4.146875\n",
      "2025-02-28 13:52:20 | Batch 6360/18424 (observations 286155-286200/829080) loss: 4.0765625\n",
      "2025-02-28 13:52:38 | Batch 6370/18424 (observations 286605-286650/829080) loss: 4.09375\n",
      "2025-02-28 13:52:57 | Batch 6380/18424 (observations 287055-287100/829080) loss: 4.109375\n",
      "2025-02-28 13:53:15 | Batch 6390/18424 (observations 287505-287550/829080) loss: 4.184375\n",
      "2025-02-28 13:53:34 | Batch 6400/18424 (observations 287955-288000/829080) loss: 4.1046875\n",
      "2025-02-28 13:53:52 | Batch 6410/18424 (observations 288405-288450/829080) loss: 4.16875\n",
      "2025-02-28 13:54:11 | Batch 6420/18424 (observations 288855-288900/829080) loss: 4.146875\n",
      "2025-02-28 13:54:29 | Batch 6430/18424 (observations 289305-289350/829080) loss: 4.13125\n",
      "2025-02-28 13:54:48 | Batch 6440/18424 (observations 289755-289800/829080) loss: 4.134375\n",
      "2025-02-28 13:55:06 | Batch 6450/18424 (observations 290205-290250/829080) loss: 4.146875\n",
      "2025-02-28 13:55:25 | Batch 6460/18424 (observations 290655-290700/829080) loss: 4.1609375\n",
      "2025-02-28 13:55:43 | Batch 6470/18424 (observations 291105-291150/829080) loss: 4.071875\n",
      "2025-02-28 13:56:02 | Batch 6480/18424 (observations 291555-291600/829080) loss: 4.1125\n",
      "2025-02-28 13:56:21 | Batch 6490/18424 (observations 292005-292050/829080) loss: 4.203125\n",
      "2025-02-28 13:56:39 | Batch 6500/18424 (observations 292455-292500/829080) loss: 4.090625\n",
      "2025-02-28 13:56:58 | Batch 6510/18424 (observations 292905-292950/829080) loss: 4.075\n",
      "2025-02-28 13:57:16 | Batch 6520/18424 (observations 293355-293400/829080) loss: 4.09375\n",
      "2025-02-28 13:57:35 | Batch 6530/18424 (observations 293805-293850/829080) loss: 4.14375\n",
      "2025-02-28 13:57:54 | Batch 6540/18424 (observations 294255-294300/829080) loss: 4.0828125\n",
      "2025-02-28 13:58:12 | Batch 6550/18424 (observations 294705-294750/829080) loss: 4.0875\n",
      "2025-02-28 13:58:31 | Batch 6560/18424 (observations 295155-295200/829080) loss: 4.14375\n",
      "2025-02-28 13:58:49 | Batch 6570/18424 (observations 295605-295650/829080) loss: 4.1484375\n",
      "2025-02-28 13:59:08 | Batch 6580/18424 (observations 296055-296100/829080) loss: 4.146875\n",
      "2025-02-28 13:59:26 | Batch 6590/18424 (observations 296505-296550/829080) loss: 4.128125\n",
      "2025-02-28 13:59:45 | Batch 6600/18424 (observations 296955-297000/829080) loss: 4.065625\n",
      "2025-02-28 14:00:04 | Batch 6610/18424 (observations 297405-297450/829080) loss: 4.09375\n",
      "2025-02-28 14:00:22 | Batch 6620/18424 (observations 297855-297900/829080) loss: 4.1046875\n",
      "2025-02-28 14:00:41 | Batch 6630/18424 (observations 298305-298350/829080) loss: 4.115625\n",
      "2025-02-28 14:00:59 | Batch 6640/18424 (observations 298755-298800/829080) loss: 4.0984375\n",
      "2025-02-28 14:01:17 | Batch 6650/18424 (observations 299205-299250/829080) loss: 4.0796875\n",
      "2025-02-28 14:01:36 | Batch 6660/18424 (observations 299655-299700/829080) loss: 4.0421875\n",
      "2025-02-28 14:01:54 | Batch 6670/18424 (observations 300105-300150/829080) loss: 4.1671875\n",
      "2025-02-28 14:02:13 | Batch 6680/18424 (observations 300555-300600/829080) loss: 4.1234375\n",
      "2025-02-28 14:02:31 | Batch 6690/18424 (observations 301005-301050/829080) loss: 4.0859375\n",
      "2025-02-28 14:02:50 | Batch 6700/18424 (observations 301455-301500/829080) loss: 4.0984375\n",
      "2025-02-28 14:03:08 | Batch 6710/18424 (observations 301905-301950/829080) loss: 4.1515625\n",
      "2025-02-28 14:03:27 | Batch 6720/18424 (observations 302355-302400/829080) loss: 4.1265625\n",
      "2025-02-28 14:03:45 | Batch 6730/18424 (observations 302805-302850/829080) loss: 4.165625\n",
      "2025-02-28 14:04:03 | Batch 6740/18424 (observations 303255-303300/829080) loss: 4.1046875\n",
      "2025-02-28 14:04:22 | Batch 6750/18424 (observations 303705-303750/829080) loss: 4.128125\n",
      "2025-02-28 14:04:41 | Batch 6760/18424 (observations 304155-304200/829080) loss: 4.078125\n",
      "2025-02-28 14:04:59 | Batch 6770/18424 (observations 304605-304650/829080) loss: 4.1046875\n",
      "2025-02-28 14:05:18 | Batch 6780/18424 (observations 305055-305100/829080) loss: 4.0953125\n",
      "2025-02-28 14:05:36 | Batch 6790/18424 (observations 305505-305550/829080) loss: 4.084375\n",
      "2025-02-28 14:05:55 | Batch 6800/18424 (observations 305955-306000/829080) loss: 4.128125\n",
      "2025-02-28 14:06:13 | Batch 6810/18424 (observations 306405-306450/829080) loss: 4.065625\n",
      "2025-02-28 14:06:32 | Batch 6820/18424 (observations 306855-306900/829080) loss: 4.05625\n",
      "2025-02-28 14:06:51 | Batch 6830/18424 (observations 307305-307350/829080) loss: 4.1\n",
      "2025-02-28 14:07:09 | Batch 6840/18424 (observations 307755-307800/829080) loss: 4.090625\n",
      "2025-02-28 14:07:28 | Batch 6850/18424 (observations 308205-308250/829080) loss: 4.1265625\n",
      "2025-02-28 14:07:46 | Batch 6860/18424 (observations 308655-308700/829080) loss: 4.065625\n",
      "2025-02-28 14:08:05 | Batch 6870/18424 (observations 309105-309150/829080) loss: 4.1390625\n",
      "2025-02-28 14:08:23 | Batch 6880/18424 (observations 309555-309600/829080) loss: 4.1328125\n",
      "2025-02-28 14:08:42 | Batch 6890/18424 (observations 310005-310050/829080) loss: 4.1078125\n",
      "2025-02-28 14:09:01 | Batch 6900/18424 (observations 310455-310500/829080) loss: 4.0640625\n",
      "2025-02-28 14:09:19 | Batch 6910/18424 (observations 310905-310950/829080) loss: 4.0765625\n",
      "2025-02-28 14:09:38 | Batch 6920/18424 (observations 311355-311400/829080) loss: 4.1\n",
      "2025-02-28 14:09:56 | Batch 6930/18424 (observations 311805-311850/829080) loss: 4.084375\n",
      "2025-02-28 14:10:15 | Batch 6940/18424 (observations 312255-312300/829080) loss: 4.140625\n",
      "2025-02-28 14:10:33 | Batch 6950/18424 (observations 312705-312750/829080) loss: 4.1390625\n",
      "2025-02-28 14:10:52 | Batch 6960/18424 (observations 313155-313200/829080) loss: 4.103125\n",
      "2025-02-28 14:11:11 | Batch 6970/18424 (observations 313605-313650/829080) loss: 4.1109375\n",
      "2025-02-28 14:11:29 | Batch 6980/18424 (observations 314055-314100/829080) loss: 4.1359375\n",
      "2025-02-28 14:11:48 | Batch 6990/18424 (observations 314505-314550/829080) loss: 4.1875\n",
      "2025-02-28 14:12:06 | Batch 7000/18424 (observations 314955-315000/829080) loss: 4.1265625\n",
      "2025-02-28 14:12:25 | Batch 7010/18424 (observations 315405-315450/829080) loss: 4.1296875\n",
      "2025-02-28 14:12:43 | Batch 7020/18424 (observations 315855-315900/829080) loss: 4.128125\n",
      "2025-02-28 14:13:02 | Batch 7030/18424 (observations 316305-316350/829080) loss: 4.1203125\n",
      "2025-02-28 14:13:20 | Batch 7040/18424 (observations 316755-316800/829080) loss: 4.08125\n",
      "2025-02-28 14:13:38 | Batch 7050/18424 (observations 317205-317250/829080) loss: 4.071875\n",
      "2025-02-28 14:13:57 | Batch 7060/18424 (observations 317655-317700/829080) loss: 4.10625\n",
      "2025-02-28 14:14:15 | Batch 7070/18424 (observations 318105-318150/829080) loss: 4.153125\n",
      "2025-02-28 14:14:34 | Batch 7080/18424 (observations 318555-318600/829080) loss: 4.046875\n",
      "2025-02-28 14:14:52 | Batch 7090/18424 (observations 319005-319050/829080) loss: 4.140625\n",
      "2025-02-28 14:15:11 | Batch 7100/18424 (observations 319455-319500/829080) loss: 4.0859375\n",
      "2025-02-28 14:15:29 | Batch 7110/18424 (observations 319905-319950/829080) loss: 4.090625\n",
      "2025-02-28 14:15:48 | Batch 7120/18424 (observations 320355-320400/829080) loss: 4.084375\n",
      "2025-02-28 14:16:06 | Batch 7130/18424 (observations 320805-320850/829080) loss: 4.115625\n",
      "2025-02-28 14:16:25 | Batch 7140/18424 (observations 321255-321300/829080) loss: 4.0703125\n",
      "2025-02-28 14:16:43 | Batch 7150/18424 (observations 321705-321750/829080) loss: 4.0796875\n",
      "2025-02-28 14:17:01 | Batch 7160/18424 (observations 322155-322200/829080) loss: 4.1296875\n",
      "2025-02-28 14:17:20 | Batch 7170/18424 (observations 322605-322650/829080) loss: 4.11875\n",
      "2025-02-28 14:17:39 | Batch 7180/18424 (observations 323055-323100/829080) loss: 4.140625\n",
      "2025-02-28 14:17:57 | Batch 7190/18424 (observations 323505-323550/829080) loss: 4.1046875\n",
      "2025-02-28 14:18:16 | Batch 7200/18424 (observations 323955-324000/829080) loss: 4.0640625\n",
      "2025-02-28 14:18:36 | Batch 7210/18424 (observations 324405-324450/829080) loss: 4.1\n",
      "2025-02-28 14:18:55 | Batch 7220/18424 (observations 324855-324900/829080) loss: 4.1625\n",
      "2025-02-28 14:19:15 | Batch 7230/18424 (observations 325305-325350/829080) loss: 4.1546875\n",
      "2025-02-28 14:19:34 | Batch 7240/18424 (observations 325755-325800/829080) loss: 4.1875\n",
      "2025-02-28 14:19:54 | Batch 7250/18424 (observations 326205-326250/829080) loss: 4.1\n",
      "2025-02-28 14:20:14 | Batch 7260/18424 (observations 326655-326700/829080) loss: 4.134375\n",
      "2025-02-28 14:20:33 | Batch 7270/18424 (observations 327105-327150/829080) loss: 4.15\n",
      "2025-02-28 14:20:53 | Batch 7280/18424 (observations 327555-327600/829080) loss: 4.1140625\n",
      "2025-02-28 14:21:13 | Batch 7290/18424 (observations 328005-328050/829080) loss: 4.0921875\n",
      "2025-02-28 14:21:33 | Batch 7300/18424 (observations 328455-328500/829080) loss: 4.1078125\n",
      "2025-02-28 14:21:52 | Batch 7310/18424 (observations 328905-328950/829080) loss: 4.0765625\n",
      "2025-02-28 14:22:12 | Batch 7320/18424 (observations 329355-329400/829080) loss: 4.165625\n",
      "2025-02-28 14:22:32 | Batch 7330/18424 (observations 329805-329850/829080) loss: 4.0890625\n",
      "2025-02-28 14:22:51 | Batch 7340/18424 (observations 330255-330300/829080) loss: 4.096875\n",
      "2025-02-28 14:23:11 | Batch 7350/18424 (observations 330705-330750/829080) loss: 4.0953125\n",
      "2025-02-28 14:23:30 | Batch 7360/18424 (observations 331155-331200/829080) loss: 4.11875\n",
      "2025-02-28 14:23:50 | Batch 7370/18424 (observations 331605-331650/829080) loss: 4.1015625\n",
      "2025-02-28 14:24:09 | Batch 7380/18424 (observations 332055-332100/829080) loss: 4.0921875\n",
      "2025-02-28 14:24:29 | Batch 7390/18424 (observations 332505-332550/829080) loss: 4.153125\n",
      "2025-02-28 14:24:48 | Batch 7400/18424 (observations 332955-333000/829080) loss: 4.1015625\n",
      "2025-02-28 14:25:09 | Batch 7410/18424 (observations 333405-333450/829080) loss: 4.1109375\n",
      "2025-02-28 14:25:28 | Batch 7420/18424 (observations 333855-333900/829080) loss: 4.10625\n",
      "2025-02-28 14:25:48 | Batch 7430/18424 (observations 334305-334350/829080) loss: 4.0890625\n",
      "2025-02-28 14:26:08 | Batch 7440/18424 (observations 334755-334800/829080) loss: 4.159375\n",
      "2025-02-28 14:26:27 | Batch 7450/18424 (observations 335205-335250/829080) loss: 4.1234375\n",
      "2025-02-28 14:26:47 | Batch 7460/18424 (observations 335655-335700/829080) loss: 4.1234375\n",
      "2025-02-28 14:27:06 | Batch 7470/18424 (observations 336105-336150/829080) loss: 4.18125\n",
      "2025-02-28 14:27:25 | Batch 7480/18424 (observations 336555-336600/829080) loss: 4.16875\n",
      "2025-02-28 14:27:45 | Batch 7490/18424 (observations 337005-337050/829080) loss: 4.1453125\n",
      "2025-02-28 14:28:04 | Batch 7500/18424 (observations 337455-337500/829080) loss: 4.1296875\n",
      "2025-02-28 14:28:23 | Batch 7510/18424 (observations 337905-337950/829080) loss: 4.0765625\n",
      "2025-02-28 14:28:43 | Batch 7520/18424 (observations 338355-338400/829080) loss: 4.0984375\n",
      "2025-02-28 14:29:03 | Batch 7530/18424 (observations 338805-338850/829080) loss: 4.0875\n",
      "2025-02-28 14:29:23 | Batch 7540/18424 (observations 339255-339300/829080) loss: 4.1234375\n",
      "2025-02-28 14:29:45 | Batch 7550/18424 (observations 339705-339750/829080) loss: 4.046875\n",
      "2025-02-28 14:30:04 | Batch 7560/18424 (observations 340155-340200/829080) loss: 4.1328125\n",
      "2025-02-28 14:30:25 | Batch 7570/18424 (observations 340605-340650/829080) loss: 4.14375\n",
      "2025-02-28 14:30:45 | Batch 7580/18424 (observations 341055-341100/829080) loss: 4.125\n",
      "2025-02-28 14:31:05 | Batch 7590/18424 (observations 341505-341550/829080) loss: 4.1625\n",
      "2025-02-28 14:31:24 | Batch 7600/18424 (observations 341955-342000/829080) loss: 4.09375\n",
      "2025-02-28 14:31:44 | Batch 7610/18424 (observations 342405-342450/829080) loss: 4.04375\n",
      "2025-02-28 14:32:04 | Batch 7620/18424 (observations 342855-342900/829080) loss: 4.0734375\n",
      "2025-02-28 14:32:25 | Batch 7630/18424 (observations 343305-343350/829080) loss: 4.08125\n",
      "2025-02-28 14:32:44 | Batch 7640/18424 (observations 343755-343800/829080) loss: 4.1125\n",
      "2025-02-28 14:33:05 | Batch 7650/18424 (observations 344205-344250/829080) loss: 4.084375\n",
      "2025-02-28 14:33:24 | Batch 7660/18424 (observations 344655-344700/829080) loss: 4.0796875\n",
      "2025-02-28 14:33:44 | Batch 7670/18424 (observations 345105-345150/829080) loss: 4.1203125\n",
      "2025-02-28 14:34:05 | Batch 7680/18424 (observations 345555-345600/829080) loss: 4.14375\n",
      "2025-02-28 14:34:27 | Batch 7690/18424 (observations 346005-346050/829080) loss: 4.0703125\n",
      "2025-02-28 14:34:49 | Batch 7700/18424 (observations 346455-346500/829080) loss: 4.0953125\n",
      "2025-02-28 14:35:11 | Batch 7710/18424 (observations 346905-346950/829080) loss: 4.075\n",
      "2025-02-28 14:35:34 | Batch 7720/18424 (observations 347355-347400/829080) loss: 4.1328125\n",
      "2025-02-28 14:35:56 | Batch 7730/18424 (observations 347805-347850/829080) loss: 4.0984375\n",
      "2025-02-28 14:36:18 | Batch 7740/18424 (observations 348255-348300/829080) loss: 4.1015625\n",
      "2025-02-28 14:36:41 | Batch 7750/18424 (observations 348705-348750/829080) loss: 4.0953125\n",
      "2025-02-28 14:37:04 | Batch 7760/18424 (observations 349155-349200/829080) loss: 4.13125\n",
      "2025-02-28 14:37:26 | Batch 7770/18424 (observations 349605-349650/829080) loss: 4.146875\n",
      "2025-02-28 14:37:48 | Batch 7780/18424 (observations 350055-350100/829080) loss: 4.0953125\n",
      "2025-02-28 14:38:10 | Batch 7790/18424 (observations 350505-350550/829080) loss: 4.11875\n",
      "2025-02-28 14:38:32 | Batch 7800/18424 (observations 350955-351000/829080) loss: 4.1140625\n",
      "2025-02-28 14:38:54 | Batch 7810/18424 (observations 351405-351450/829080) loss: 4.0765625\n",
      "2025-02-28 14:39:17 | Batch 7820/18424 (observations 351855-351900/829080) loss: 4.1203125\n",
      "2025-02-28 14:39:38 | Batch 7830/18424 (observations 352305-352350/829080) loss: 4.0546875\n",
      "2025-02-28 14:40:01 | Batch 7840/18424 (observations 352755-352800/829080) loss: 4.09375\n",
      "2025-02-28 14:40:22 | Batch 7850/18424 (observations 353205-353250/829080) loss: 4.084375\n",
      "2025-02-28 14:40:44 | Batch 7860/18424 (observations 353655-353700/829080) loss: 4.1203125\n",
      "2025-02-28 14:41:06 | Batch 7870/18424 (observations 354105-354150/829080) loss: 4.1015625\n",
      "2025-02-28 14:41:28 | Batch 7880/18424 (observations 354555-354600/829080) loss: 4.08125\n",
      "2025-02-28 14:41:50 | Batch 7890/18424 (observations 355005-355050/829080) loss: 4.178125\n",
      "2025-02-28 14:42:12 | Batch 7900/18424 (observations 355455-355500/829080) loss: 4.0578125\n",
      "2025-02-28 14:42:35 | Batch 7910/18424 (observations 355905-355950/829080) loss: 4.128125\n",
      "2025-02-28 14:42:57 | Batch 7920/18424 (observations 356355-356400/829080) loss: 4.1390625\n",
      "2025-02-28 14:43:20 | Batch 7930/18424 (observations 356805-356850/829080) loss: 4.1453125\n",
      "2025-02-28 14:43:43 | Batch 7940/18424 (observations 357255-357300/829080) loss: 4.1375\n",
      "2025-02-28 14:44:06 | Batch 7950/18424 (observations 357705-357750/829080) loss: 4.0515625\n",
      "2025-02-28 14:44:29 | Batch 7960/18424 (observations 358155-358200/829080) loss: 4.090625\n",
      "2025-02-28 14:44:51 | Batch 7970/18424 (observations 358605-358650/829080) loss: 4.115625\n",
      "2025-02-28 14:45:13 | Batch 7980/18424 (observations 359055-359100/829080) loss: 4.1234375\n",
      "2025-02-28 14:45:34 | Batch 7990/18424 (observations 359505-359550/829080) loss: 4.115625\n",
      "2025-02-28 14:45:56 | Batch 8000/18424 (observations 359955-360000/829080) loss: 4.0640625\n",
      "2025-02-28 14:46:18 | Batch 8010/18424 (observations 360405-360450/829080) loss: 4.153125\n",
      "2025-02-28 14:46:39 | Batch 8020/18424 (observations 360855-360900/829080) loss: 4.1203125\n",
      "2025-02-28 14:47:01 | Batch 8030/18424 (observations 361305-361350/829080) loss: 4.090625\n",
      "2025-02-28 14:47:23 | Batch 8040/18424 (observations 361755-361800/829080) loss: 4.1703125\n",
      "2025-02-28 14:47:44 | Batch 8050/18424 (observations 362205-362250/829080) loss: 4.08125\n",
      "2025-02-28 14:48:06 | Batch 8060/18424 (observations 362655-362700/829080) loss: 4.18125\n",
      "2025-02-28 14:48:28 | Batch 8070/18424 (observations 363105-363150/829080) loss: 4.13125\n",
      "2025-02-28 14:48:50 | Batch 8080/18424 (observations 363555-363600/829080) loss: 4.178125\n",
      "2025-02-28 14:49:12 | Batch 8090/18424 (observations 364005-364050/829080) loss: 4.0671875\n",
      "2025-02-28 14:49:35 | Batch 8100/18424 (observations 364455-364500/829080) loss: 4.11875\n",
      "2025-02-28 14:49:57 | Batch 8110/18424 (observations 364905-364950/829080) loss: 4.0265625\n",
      "2025-02-28 14:50:18 | Batch 8120/18424 (observations 365355-365400/829080) loss: 4.1421875\n",
      "2025-02-28 14:50:40 | Batch 8130/18424 (observations 365805-365850/829080) loss: 4.1140625\n",
      "2025-02-28 14:51:02 | Batch 8140/18424 (observations 366255-366300/829080) loss: 4.06875\n",
      "2025-02-28 14:51:24 | Batch 8150/18424 (observations 366705-366750/829080) loss: 4.0984375\n",
      "2025-02-28 14:51:46 | Batch 8160/18424 (observations 367155-367200/829080) loss: 4.1015625\n",
      "2025-02-28 14:52:08 | Batch 8170/18424 (observations 367605-367650/829080) loss: 4.13125\n",
      "2025-02-28 14:52:30 | Batch 8180/18424 (observations 368055-368100/829080) loss: 4.1359375\n",
      "2025-02-28 14:52:52 | Batch 8190/18424 (observations 368505-368550/829080) loss: 4.109375\n",
      "2025-02-28 14:53:14 | Batch 8200/18424 (observations 368955-369000/829080) loss: 4.0796875\n",
      "2025-02-28 14:53:36 | Batch 8210/18424 (observations 369405-369450/829080) loss: 4.0890625\n",
      "2025-02-28 14:53:57 | Batch 8220/18424 (observations 369855-369900/829080) loss: 4.1203125\n",
      "2025-02-28 14:54:20 | Batch 8230/18424 (observations 370305-370350/829080) loss: 4.121875\n",
      "2025-02-28 14:54:41 | Batch 8240/18424 (observations 370755-370800/829080) loss: 4.15\n",
      "2025-02-28 14:55:03 | Batch 8250/18424 (observations 371205-371250/829080) loss: 4.1375\n",
      "2025-02-28 14:55:25 | Batch 8260/18424 (observations 371655-371700/829080) loss: 4.146875\n",
      "2025-02-28 14:55:47 | Batch 8270/18424 (observations 372105-372150/829080) loss: 4.1015625\n",
      "2025-02-28 14:56:08 | Batch 8280/18424 (observations 372555-372600/829080) loss: 4.1390625\n",
      "2025-02-28 14:56:30 | Batch 8290/18424 (observations 373005-373050/829080) loss: 4.0609375\n",
      "2025-02-28 14:56:52 | Batch 8300/18424 (observations 373455-373500/829080) loss: 4.16875\n",
      "2025-02-28 14:57:14 | Batch 8310/18424 (observations 373905-373950/829080) loss: 4.159375\n",
      "2025-02-28 14:57:35 | Batch 8320/18424 (observations 374355-374400/829080) loss: 4.165625\n",
      "2025-02-28 14:57:57 | Batch 8330/18424 (observations 374805-374850/829080) loss: 4.128125\n",
      "2025-02-28 14:58:19 | Batch 8340/18424 (observations 375255-375300/829080) loss: 4.109375\n",
      "2025-02-28 14:58:41 | Batch 8350/18424 (observations 375705-375750/829080) loss: 4.071875\n",
      "2025-02-28 14:59:03 | Batch 8360/18424 (observations 376155-376200/829080) loss: 4.1359375\n",
      "2025-02-28 14:59:25 | Batch 8370/18424 (observations 376605-376650/829080) loss: 4.115625\n",
      "2025-02-28 14:59:46 | Batch 8380/18424 (observations 377055-377100/829080) loss: 4.0734375\n",
      "2025-02-28 15:00:08 | Batch 8390/18424 (observations 377505-377550/829080) loss: 4.196875\n",
      "2025-02-28 15:00:30 | Batch 8400/18424 (observations 377955-378000/829080) loss: 4.1171875\n",
      "2025-02-28 15:00:52 | Batch 8410/18424 (observations 378405-378450/829080) loss: 4.084375\n",
      "2025-02-28 15:01:14 | Batch 8420/18424 (observations 378855-378900/829080) loss: 4.115625\n",
      "2025-02-28 15:01:35 | Batch 8430/18424 (observations 379305-379350/829080) loss: 4.153125\n",
      "2025-02-28 15:01:57 | Batch 8440/18424 (observations 379755-379800/829080) loss: 4.1\n",
      "2025-02-28 15:02:19 | Batch 8450/18424 (observations 380205-380250/829080) loss: 4.13125\n",
      "2025-02-28 15:02:40 | Batch 8460/18424 (observations 380655-380700/829080) loss: 4.15\n",
      "2025-02-28 15:03:02 | Batch 8470/18424 (observations 381105-381150/829080) loss: 4.153125\n",
      "2025-02-28 15:03:23 | Batch 8480/18424 (observations 381555-381600/829080) loss: 4.09375\n",
      "2025-02-28 15:03:45 | Batch 8490/18424 (observations 382005-382050/829080) loss: 4.125\n",
      "2025-02-28 15:04:07 | Batch 8500/18424 (observations 382455-382500/829080) loss: 4.090625\n",
      "2025-02-28 15:04:29 | Batch 8510/18424 (observations 382905-382950/829080) loss: 4.1375\n",
      "2025-02-28 15:04:51 | Batch 8520/18424 (observations 383355-383400/829080) loss: 4.1046875\n",
      "2025-02-28 15:05:12 | Batch 8530/18424 (observations 383805-383850/829080) loss: 4.065625\n",
      "2025-02-28 15:05:34 | Batch 8540/18424 (observations 384255-384300/829080) loss: 4.1140625\n",
      "2025-02-28 15:05:56 | Batch 8550/18424 (observations 384705-384750/829080) loss: 4.175\n",
      "2025-02-28 15:06:18 | Batch 8560/18424 (observations 385155-385200/829080) loss: 4.0953125\n",
      "2025-02-28 15:06:39 | Batch 8570/18424 (observations 385605-385650/829080) loss: 4.134375\n",
      "2025-02-28 15:07:01 | Batch 8580/18424 (observations 386055-386100/829080) loss: 4.1015625\n",
      "2025-02-28 15:07:23 | Batch 8590/18424 (observations 386505-386550/829080) loss: 4.146875\n",
      "2025-02-28 15:07:45 | Batch 8600/18424 (observations 386955-387000/829080) loss: 4.1078125\n",
      "2025-02-28 15:08:07 | Batch 8610/18424 (observations 387405-387450/829080) loss: 4.14375\n",
      "2025-02-28 15:08:28 | Batch 8620/18424 (observations 387855-387900/829080) loss: 4.125\n",
      "2025-02-28 15:08:50 | Batch 8630/18424 (observations 388305-388350/829080) loss: 4.1\n",
      "2025-02-28 15:09:12 | Batch 8640/18424 (observations 388755-388800/829080) loss: 4.103125\n",
      "2025-02-28 15:09:33 | Batch 8650/18424 (observations 389205-389250/829080) loss: 4.1328125\n",
      "2025-02-28 15:09:55 | Batch 8660/18424 (observations 389655-389700/829080) loss: 4.171875\n",
      "2025-02-28 15:10:17 | Batch 8670/18424 (observations 390105-390150/829080) loss: 4.0953125\n",
      "2025-02-28 15:10:39 | Batch 8680/18424 (observations 390555-390600/829080) loss: 4.1125\n",
      "2025-02-28 15:11:01 | Batch 8690/18424 (observations 391005-391050/829080) loss: 4.0265625\n",
      "2025-02-28 15:11:22 | Batch 8700/18424 (observations 391455-391500/829080) loss: 4.1140625\n",
      "2025-02-28 15:11:44 | Batch 8710/18424 (observations 391905-391950/829080) loss: 4.0984375\n",
      "2025-02-28 15:12:06 | Batch 8720/18424 (observations 392355-392400/829080) loss: 4.1015625\n",
      "2025-02-28 15:12:28 | Batch 8730/18424 (observations 392805-392850/829080) loss: 4.1078125\n",
      "2025-02-28 15:12:49 | Batch 8740/18424 (observations 393255-393300/829080) loss: 4.084375\n",
      "2025-02-28 15:13:11 | Batch 8750/18424 (observations 393705-393750/829080) loss: 4.0953125\n",
      "2025-02-28 15:13:33 | Batch 8760/18424 (observations 394155-394200/829080) loss: 4.0578125\n",
      "2025-02-28 15:13:55 | Batch 8770/18424 (observations 394605-394650/829080) loss: 4.0640625\n",
      "2025-02-28 15:14:16 | Batch 8780/18424 (observations 395055-395100/829080) loss: 4.1484375\n",
      "2025-02-28 15:14:38 | Batch 8790/18424 (observations 395505-395550/829080) loss: 4.1015625\n",
      "2025-02-28 15:15:00 | Batch 8800/18424 (observations 395955-396000/829080) loss: 4.0953125\n",
      "2025-02-28 15:15:22 | Batch 8810/18424 (observations 396405-396450/829080) loss: 4.05625\n",
      "2025-02-28 15:15:43 | Batch 8820/18424 (observations 396855-396900/829080) loss: 4.0671875\n",
      "2025-02-28 15:16:05 | Batch 8830/18424 (observations 397305-397350/829080) loss: 4.0984375\n",
      "2025-02-28 15:16:27 | Batch 8840/18424 (observations 397755-397800/829080) loss: 4.1421875\n",
      "2025-02-28 15:16:49 | Batch 8850/18424 (observations 398205-398250/829080) loss: 4.1078125\n",
      "2025-02-28 15:17:10 | Batch 8860/18424 (observations 398655-398700/829080) loss: 4.1265625\n",
      "2025-02-28 15:17:32 | Batch 8870/18424 (observations 399105-399150/829080) loss: 4.121875\n",
      "2025-02-28 15:17:54 | Batch 8880/18424 (observations 399555-399600/829080) loss: 4.08125\n",
      "2025-02-28 15:18:16 | Batch 8890/18424 (observations 400005-400050/829080) loss: 4.140625\n",
      "2025-02-28 15:18:39 | Batch 8900/18424 (observations 400455-400500/829080) loss: 4.1421875\n",
      "2025-02-28 15:19:01 | Batch 8910/18424 (observations 400905-400950/829080) loss: 4.0875\n",
      "2025-02-28 15:19:24 | Batch 8920/18424 (observations 401355-401400/829080) loss: 4.075\n",
      "2025-02-28 15:19:46 | Batch 8930/18424 (observations 401805-401850/829080) loss: 4.0859375\n",
      "2025-02-28 15:20:09 | Batch 8940/18424 (observations 402255-402300/829080) loss: 4.159375\n",
      "2025-02-28 15:20:31 | Batch 8950/18424 (observations 402705-402750/829080) loss: 4.1421875\n",
      "2025-02-28 15:20:53 | Batch 8960/18424 (observations 403155-403200/829080) loss: 4.1328125\n",
      "2025-02-28 15:21:15 | Batch 8970/18424 (observations 403605-403650/829080) loss: 4.115625\n",
      "2025-02-28 15:21:37 | Batch 8980/18424 (observations 404055-404100/829080) loss: 4.084375\n",
      "2025-02-28 15:21:59 | Batch 8990/18424 (observations 404505-404550/829080) loss: 4.1078125\n",
      "2025-02-28 15:22:21 | Batch 9000/18424 (observations 404955-405000/829080) loss: 4.084375\n",
      "2025-02-28 15:22:43 | Batch 9010/18424 (observations 405405-405450/829080) loss: 4.140625\n",
      "2025-02-28 15:23:05 | Batch 9020/18424 (observations 405855-405900/829080) loss: 4.121875\n",
      "2025-02-28 15:23:28 | Batch 9030/18424 (observations 406305-406350/829080) loss: 4.1171875\n",
      "2025-02-28 15:23:50 | Batch 9040/18424 (observations 406755-406800/829080) loss: 4.0953125\n",
      "2025-02-28 15:24:13 | Batch 9050/18424 (observations 407205-407250/829080) loss: 4.0890625\n",
      "2025-02-28 15:24:36 | Batch 9060/18424 (observations 407655-407700/829080) loss: 4.103125\n",
      "2025-02-28 15:24:58 | Batch 9070/18424 (observations 408105-408150/829080) loss: 4.0921875\n",
      "2025-02-28 15:25:21 | Batch 9080/18424 (observations 408555-408600/829080) loss: 4.0875\n",
      "2025-02-28 15:25:44 | Batch 9090/18424 (observations 409005-409050/829080) loss: 4.0640625\n",
      "2025-02-28 15:26:08 | Batch 9100/18424 (observations 409455-409500/829080) loss: 4.0796875\n",
      "2025-02-28 15:26:30 | Batch 9110/18424 (observations 409905-409950/829080) loss: 4.1015625\n",
      "2025-02-28 15:26:52 | Batch 9120/18424 (observations 410355-410400/829080) loss: 4.1296875\n",
      "2025-02-28 15:27:14 | Batch 9130/18424 (observations 410805-410850/829080) loss: 4.075\n",
      "2025-02-28 15:27:36 | Batch 9140/18424 (observations 411255-411300/829080) loss: 4.1359375\n",
      "2025-02-28 15:27:58 | Batch 9150/18424 (observations 411705-411750/829080) loss: 4.09375\n",
      "2025-02-28 15:28:20 | Batch 9160/18424 (observations 412155-412200/829080) loss: 4.1265625\n",
      "2025-02-28 15:28:42 | Batch 9170/18424 (observations 412605-412650/829080) loss: 4.05625\n",
      "2025-02-28 15:29:04 | Batch 9180/18424 (observations 413055-413100/829080) loss: 4.146875\n",
      "2025-02-28 15:29:27 | Batch 9190/18424 (observations 413505-413550/829080) loss: 4.1453125\n",
      "2025-02-28 15:29:50 | Batch 9200/18424 (observations 413955-414000/829080) loss: 4.1265625\n",
      "2025-02-28 15:30:12 | Batch 9210/18424 (observations 414405-414450/829080) loss: 4.121875\n",
      "2025-02-28 15:30:35 | Batch 9220/18424 (observations 414855-414900/829080) loss: 4.0859375\n",
      "2025-02-28 15:30:57 | Batch 9230/18424 (observations 415305-415350/829080) loss: 4.1453125\n",
      "2025-02-28 15:31:20 | Batch 9240/18424 (observations 415755-415800/829080) loss: 4.134375\n",
      "2025-02-28 15:31:43 | Batch 9250/18424 (observations 416205-416250/829080) loss: 4.1140625\n",
      "2025-02-28 15:32:06 | Batch 9260/18424 (observations 416655-416700/829080) loss: 4.103125\n",
      "2025-02-28 15:32:28 | Batch 9270/18424 (observations 417105-417150/829080) loss: 4.0609375\n",
      "2025-02-28 15:32:50 | Batch 9280/18424 (observations 417555-417600/829080) loss: 4.1046875\n",
      "2025-02-28 15:33:12 | Batch 9290/18424 (observations 418005-418050/829080) loss: 4.0671875\n",
      "2025-02-28 15:33:34 | Batch 9300/18424 (observations 418455-418500/829080) loss: 4.19375\n",
      "2025-02-28 15:33:57 | Batch 9310/18424 (observations 418905-418950/829080) loss: 4.1546875\n",
      "2025-02-28 15:34:20 | Batch 9320/18424 (observations 419355-419400/829080) loss: 4.128125\n",
      "2025-02-28 15:34:42 | Batch 9330/18424 (observations 419805-419850/829080) loss: 4.109375\n",
      "2025-02-28 15:35:05 | Batch 9340/18424 (observations 420255-420300/829080) loss: 4.14375\n",
      "2025-02-28 15:35:28 | Batch 9350/18424 (observations 420705-420750/829080) loss: 4.0796875\n",
      "2025-02-28 15:35:50 | Batch 9360/18424 (observations 421155-421200/829080) loss: 4.1765625\n",
      "2025-02-28 15:36:13 | Batch 9370/18424 (observations 421605-421650/829080) loss: 4.065625\n",
      "2025-02-28 15:36:35 | Batch 9380/18424 (observations 422055-422100/829080) loss: 4.1265625\n",
      "2025-02-28 15:36:58 | Batch 9390/18424 (observations 422505-422550/829080) loss: 4.1359375\n",
      "2025-02-28 15:37:21 | Batch 9400/18424 (observations 422955-423000/829080) loss: 4.125\n",
      "2025-02-28 15:37:43 | Batch 9410/18424 (observations 423405-423450/829080) loss: 4.059375\n",
      "2025-02-28 15:38:05 | Batch 9420/18424 (observations 423855-423900/829080) loss: 4.1625\n",
      "2025-02-28 15:38:28 | Batch 9430/18424 (observations 424305-424350/829080) loss: 4.1609375\n",
      "2025-02-28 15:38:51 | Batch 9440/18424 (observations 424755-424800/829080) loss: 4.11875\n",
      "2025-02-28 15:39:13 | Batch 9450/18424 (observations 425205-425250/829080) loss: 4.08125\n",
      "2025-02-28 15:39:35 | Batch 9460/18424 (observations 425655-425700/829080) loss: 4.0875\n",
      "2025-02-28 15:39:57 | Batch 9470/18424 (observations 426105-426150/829080) loss: 4.121875\n",
      "2025-02-28 15:40:20 | Batch 9480/18424 (observations 426555-426600/829080) loss: 4.084375\n",
      "2025-02-28 15:40:42 | Batch 9490/18424 (observations 427005-427050/829080) loss: 4.0828125\n",
      "2025-02-28 15:41:04 | Batch 9500/18424 (observations 427455-427500/829080) loss: 4.14375\n",
      "2025-02-28 15:41:28 | Batch 9510/18424 (observations 427905-427950/829080) loss: 4.128125\n",
      "2025-02-28 15:41:52 | Batch 9520/18424 (observations 428355-428400/829080) loss: 4.09375\n",
      "2025-02-28 15:42:14 | Batch 9530/18424 (observations 428805-428850/829080) loss: 4.1375\n",
      "2025-02-28 15:42:37 | Batch 9540/18424 (observations 429255-429300/829080) loss: 4.1078125\n",
      "2025-02-28 15:42:59 | Batch 9550/18424 (observations 429705-429750/829080) loss: 4.121875\n",
      "2025-02-28 15:43:21 | Batch 9560/18424 (observations 430155-430200/829080) loss: 4.109375\n",
      "2025-02-28 15:43:43 | Batch 9570/18424 (observations 430605-430650/829080) loss: 4.09375\n",
      "2025-02-28 15:44:05 | Batch 9580/18424 (observations 431055-431100/829080) loss: 4.09375\n",
      "2025-02-28 15:44:28 | Batch 9590/18424 (observations 431505-431550/829080) loss: 4.1171875\n",
      "2025-02-28 15:44:51 | Batch 9600/18424 (observations 431955-432000/829080) loss: 4.1640625\n",
      "2025-02-28 15:45:13 | Batch 9610/18424 (observations 432405-432450/829080) loss: 4.071875\n",
      "2025-02-28 15:45:35 | Batch 9620/18424 (observations 432855-432900/829080) loss: 4.0359375\n",
      "2025-02-28 15:45:57 | Batch 9630/18424 (observations 433305-433350/829080) loss: 4.140625\n",
      "2025-02-28 15:46:19 | Batch 9640/18424 (observations 433755-433800/829080) loss: 4.0921875\n",
      "2025-02-28 15:46:40 | Batch 9650/18424 (observations 434205-434250/829080) loss: 4.0578125\n",
      "2025-02-28 15:47:02 | Batch 9660/18424 (observations 434655-434700/829080) loss: 4.1203125\n",
      "2025-02-28 15:47:24 | Batch 9670/18424 (observations 435105-435150/829080) loss: 4.1171875\n",
      "2025-02-28 15:47:46 | Batch 9680/18424 (observations 435555-435600/829080) loss: 4.103125\n",
      "2025-02-28 15:48:08 | Batch 9690/18424 (observations 436005-436050/829080) loss: 4.1421875\n",
      "2025-02-28 15:48:29 | Batch 9700/18424 (observations 436455-436500/829080) loss: 4.0328125\n",
      "2025-02-28 15:48:50 | Batch 9710/18424 (observations 436905-436950/829080) loss: 4.0796875\n",
      "2025-02-28 15:49:11 | Batch 9720/18424 (observations 437355-437400/829080) loss: 4.06875\n",
      "2025-02-28 15:49:31 | Batch 9730/18424 (observations 437805-437850/829080) loss: 4.1421875\n",
      "2025-02-28 15:49:52 | Batch 9740/18424 (observations 438255-438300/829080) loss: 4.153125\n",
      "2025-02-28 15:50:13 | Batch 9750/18424 (observations 438705-438750/829080) loss: 4.140625\n",
      "2025-02-28 15:50:33 | Batch 9760/18424 (observations 439155-439200/829080) loss: 4.0796875\n",
      "2025-02-28 15:50:54 | Batch 9770/18424 (observations 439605-439650/829080) loss: 4.065625\n",
      "2025-02-28 15:51:15 | Batch 9780/18424 (observations 440055-440100/829080) loss: 4.11875\n",
      "2025-02-28 15:51:36 | Batch 9790/18424 (observations 440505-440550/829080) loss: 4.1203125\n",
      "2025-02-28 15:51:56 | Batch 9800/18424 (observations 440955-441000/829080) loss: 4.0890625\n",
      "2025-02-28 15:52:17 | Batch 9810/18424 (observations 441405-441450/829080) loss: 4.1296875\n",
      "2025-02-28 15:52:37 | Batch 9820/18424 (observations 441855-441900/829080) loss: 4.140625\n",
      "2025-02-28 15:52:57 | Batch 9830/18424 (observations 442305-442350/829080) loss: 4.090625\n",
      "2025-02-28 15:53:17 | Batch 9840/18424 (observations 442755-442800/829080) loss: 4.075\n",
      "2025-02-28 15:53:38 | Batch 9850/18424 (observations 443205-443250/829080) loss: 4.0828125\n",
      "2025-02-28 15:53:58 | Batch 9860/18424 (observations 443655-443700/829080) loss: 4.1640625\n",
      "2025-02-28 15:54:19 | Batch 9870/18424 (observations 444105-444150/829080) loss: 4.046875\n",
      "2025-02-28 15:54:41 | Batch 9880/18424 (observations 444555-444600/829080) loss: 4.134375\n",
      "2025-02-28 15:55:02 | Batch 9890/18424 (observations 445005-445050/829080) loss: 4.059375\n",
      "2025-02-28 15:55:23 | Batch 9900/18424 (observations 445455-445500/829080) loss: 4.078125\n",
      "2025-02-28 15:55:45 | Batch 9910/18424 (observations 445905-445950/829080) loss: 4.1375\n",
      "2025-02-28 15:56:06 | Batch 9920/18424 (observations 446355-446400/829080) loss: 4.071875\n",
      "2025-02-28 15:56:26 | Batch 9930/18424 (observations 446805-446850/829080) loss: 4.159375\n",
      "2025-02-28 15:56:47 | Batch 9940/18424 (observations 447255-447300/829080) loss: 4.0875\n",
      "2025-02-28 15:57:08 | Batch 9950/18424 (observations 447705-447750/829080) loss: 4.0984375\n",
      "2025-02-28 15:57:30 | Batch 9960/18424 (observations 448155-448200/829080) loss: 4.1125\n",
      "2025-02-28 15:57:51 | Batch 9970/18424 (observations 448605-448650/829080) loss: 4.121875\n",
      "2025-02-28 15:58:11 | Batch 9980/18424 (observations 449055-449100/829080) loss: 4.075\n",
      "2025-02-28 15:58:32 | Batch 9990/18424 (observations 449505-449550/829080) loss: 4.1578125\n",
      "2025-02-28 15:58:53 | Batch 10000/18424 (observations 449955-450000/829080) loss: 4.1296875\n",
      "2025-02-28 15:59:15 | Batch 10010/18424 (observations 450405-450450/829080) loss: 4.1125\n",
      "2025-02-28 15:59:37 | Batch 10020/18424 (observations 450855-450900/829080) loss: 4.1453125\n",
      "2025-02-28 15:59:57 | Batch 10030/18424 (observations 451305-451350/829080) loss: 4.10625\n",
      "2025-02-28 16:00:19 | Batch 10040/18424 (observations 451755-451800/829080) loss: 4.121875\n",
      "2025-02-28 16:00:39 | Batch 10050/18424 (observations 452205-452250/829080) loss: 4.075\n",
      "2025-02-28 16:01:00 | Batch 10060/18424 (observations 452655-452700/829080) loss: 4.15\n",
      "2025-02-28 16:01:21 | Batch 10070/18424 (observations 453105-453150/829080) loss: 4.0890625\n",
      "2025-02-28 16:01:42 | Batch 10080/18424 (observations 453555-453600/829080) loss: 4.0890625\n",
      "2025-02-28 16:02:03 | Batch 10090/18424 (observations 454005-454050/829080) loss: 4.115625\n",
      "2025-02-28 16:02:24 | Batch 10100/18424 (observations 454455-454500/829080) loss: 4.1234375\n",
      "2025-02-28 16:02:44 | Batch 10110/18424 (observations 454905-454950/829080) loss: 4.0828125\n",
      "2025-02-28 16:03:05 | Batch 10120/18424 (observations 455355-455400/829080) loss: 4.075\n",
      "2025-02-28 16:03:26 | Batch 10130/18424 (observations 455805-455850/829080) loss: 4.0578125\n",
      "2025-02-28 16:03:46 | Batch 10140/18424 (observations 456255-456300/829080) loss: 4.1125\n",
      "2025-02-28 16:04:07 | Batch 10150/18424 (observations 456705-456750/829080) loss: 4.0890625\n",
      "2025-02-28 16:04:28 | Batch 10160/18424 (observations 457155-457200/829080) loss: 4.0390625\n",
      "2025-02-28 16:04:49 | Batch 10170/18424 (observations 457605-457650/829080) loss: 4.121875\n",
      "2025-02-28 16:05:11 | Batch 10180/18424 (observations 458055-458100/829080) loss: 4.146875\n",
      "2025-02-28 16:05:32 | Batch 10190/18424 (observations 458505-458550/829080) loss: 4.05\n",
      "2025-02-28 16:05:53 | Batch 10200/18424 (observations 458955-459000/829080) loss: 4.0671875\n",
      "2025-02-28 16:06:14 | Batch 10210/18424 (observations 459405-459450/829080) loss: 4.1015625\n",
      "2025-02-28 16:06:34 | Batch 10220/18424 (observations 459855-459900/829080) loss: 4.1375\n",
      "2025-02-28 16:06:56 | Batch 10230/18424 (observations 460305-460350/829080) loss: 4.096875\n",
      "2025-02-28 16:07:17 | Batch 10240/18424 (observations 460755-460800/829080) loss: 4.0796875\n",
      "2025-02-28 16:07:39 | Batch 10250/18424 (observations 461205-461250/829080) loss: 4.11875\n",
      "2025-02-28 16:08:01 | Batch 10260/18424 (observations 461655-461700/829080) loss: 4.184375\n",
      "2025-02-28 16:08:22 | Batch 10270/18424 (observations 462105-462150/829080) loss: 4.11875\n",
      "2025-02-28 16:08:42 | Batch 10280/18424 (observations 462555-462600/829080) loss: 4.1203125\n",
      "2025-02-28 16:09:03 | Batch 10290/18424 (observations 463005-463050/829080) loss: 4.125\n",
      "2025-02-28 16:09:24 | Batch 10300/18424 (observations 463455-463500/829080) loss: 4.1359375\n",
      "2025-02-28 16:09:46 | Batch 10310/18424 (observations 463905-463950/829080) loss: 4.1640625\n",
      "2025-02-28 16:10:06 | Batch 10320/18424 (observations 464355-464400/829080) loss: 4.175\n",
      "2025-02-28 16:10:27 | Batch 10330/18424 (observations 464805-464850/829080) loss: 4.15625\n",
      "2025-02-28 16:10:49 | Batch 10340/18424 (observations 465255-465300/829080) loss: 4.1\n",
      "2025-02-28 16:11:09 | Batch 10350/18424 (observations 465705-465750/829080) loss: 4.0921875\n",
      "2025-02-28 16:11:30 | Batch 10360/18424 (observations 466155-466200/829080) loss: 4.171875\n",
      "2025-02-28 16:11:51 | Batch 10370/18424 (observations 466605-466650/829080) loss: 4.1328125\n",
      "2025-02-28 16:12:12 | Batch 10380/18424 (observations 467055-467100/829080) loss: 4.1171875\n",
      "2025-02-28 16:12:33 | Batch 10390/18424 (observations 467505-467550/829080) loss: 4.128125\n",
      "2025-02-28 16:12:55 | Batch 10400/18424 (observations 467955-468000/829080) loss: 4.1328125\n",
      "2025-02-28 16:13:16 | Batch 10410/18424 (observations 468405-468450/829080) loss: 4.1390625\n",
      "2025-02-28 16:13:36 | Batch 10420/18424 (observations 468855-468900/829080) loss: 4.121875\n",
      "2025-02-28 16:13:57 | Batch 10430/18424 (observations 469305-469350/829080) loss: 4.1078125\n",
      "2025-02-28 16:14:18 | Batch 10440/18424 (observations 469755-469800/829080) loss: 4.15625\n",
      "2025-02-28 16:14:39 | Batch 10450/18424 (observations 470205-470250/829080) loss: 4.128125\n",
      "2025-02-28 16:15:00 | Batch 10460/18424 (observations 470655-470700/829080) loss: 4.0609375\n",
      "2025-02-28 16:15:21 | Batch 10470/18424 (observations 471105-471150/829080) loss: 4.121875\n",
      "2025-02-28 16:15:41 | Batch 10480/18424 (observations 471555-471600/829080) loss: 4.0828125\n",
      "2025-02-28 16:16:02 | Batch 10490/18424 (observations 472005-472050/829080) loss: 4.1875\n",
      "2025-02-28 16:16:23 | Batch 10500/18424 (observations 472455-472500/829080) loss: 4.13125\n",
      "2025-02-28 16:16:43 | Batch 10510/18424 (observations 472905-472950/829080) loss: 4.125\n",
      "2025-02-28 16:17:05 | Batch 10520/18424 (observations 473355-473400/829080) loss: 4.1453125\n",
      "2025-02-28 16:17:28 | Batch 10530/18424 (observations 473805-473850/829080) loss: 4.0640625\n",
      "2025-02-28 16:17:51 | Batch 10540/18424 (observations 474255-474300/829080) loss: 4.159375\n",
      "2025-02-28 16:18:13 | Batch 10550/18424 (observations 474705-474750/829080) loss: 4.1671875\n",
      "2025-02-28 16:18:34 | Batch 10560/18424 (observations 475155-475200/829080) loss: 4.0953125\n",
      "2025-02-28 16:18:55 | Batch 10570/18424 (observations 475605-475650/829080) loss: 4.0453125\n",
      "2025-02-28 16:19:17 | Batch 10580/18424 (observations 476055-476100/829080) loss: 4.084375\n",
      "2025-02-28 16:19:38 | Batch 10590/18424 (observations 476505-476550/829080) loss: 4.05\n",
      "2025-02-28 16:20:00 | Batch 10600/18424 (observations 476955-477000/829080) loss: 4.08125\n",
      "2025-02-28 16:20:21 | Batch 10610/18424 (observations 477405-477450/829080) loss: 4.03125\n",
      "2025-02-28 16:20:42 | Batch 10620/18424 (observations 477855-477900/829080) loss: 4.146875\n",
      "2025-02-28 16:21:03 | Batch 10630/18424 (observations 478305-478350/829080) loss: 4.0765625\n",
      "2025-02-28 16:21:24 | Batch 10640/18424 (observations 478755-478800/829080) loss: 4.0859375\n",
      "2025-02-28 16:21:46 | Batch 10650/18424 (observations 479205-479250/829080) loss: 4.059375\n",
      "2025-02-28 16:22:06 | Batch 10660/18424 (observations 479655-479700/829080) loss: 4.075\n",
      "2025-02-28 16:22:28 | Batch 10670/18424 (observations 480105-480150/829080) loss: 4.084375\n",
      "2025-02-28 16:22:50 | Batch 10680/18424 (observations 480555-480600/829080) loss: 4.0609375\n",
      "2025-02-28 16:23:10 | Batch 10690/18424 (observations 481005-481050/829080) loss: 4.065625\n",
      "2025-02-28 16:23:31 | Batch 10700/18424 (observations 481455-481500/829080) loss: 4.0453125\n",
      "2025-02-28 16:23:51 | Batch 10710/18424 (observations 481905-481950/829080) loss: 4.078125\n",
      "2025-02-28 16:24:13 | Batch 10720/18424 (observations 482355-482400/829080) loss: 4.06875\n",
      "2025-02-28 16:24:35 | Batch 10730/18424 (observations 482805-482850/829080) loss: 4.103125\n",
      "2025-02-28 16:24:56 | Batch 10740/18424 (observations 483255-483300/829080) loss: 4.03125\n",
      "2025-02-28 16:25:18 | Batch 10750/18424 (observations 483705-483750/829080) loss: 4.11875\n",
      "2025-02-28 16:25:39 | Batch 10760/18424 (observations 484155-484200/829080) loss: 4.171875\n",
      "2025-02-28 16:25:59 | Batch 10770/18424 (observations 484605-484650/829080) loss: 4.075\n",
      "2025-02-28 16:26:20 | Batch 10780/18424 (observations 485055-485100/829080) loss: 4.034375\n",
      "2025-02-28 16:26:42 | Batch 10790/18424 (observations 485505-485550/829080) loss: 4.09375\n",
      "2025-02-28 16:27:03 | Batch 10800/18424 (observations 485955-486000/829080) loss: 4.0859375\n",
      "2025-02-28 16:27:24 | Batch 10810/18424 (observations 486405-486450/829080) loss: 4.0578125\n",
      "2025-02-28 16:27:46 | Batch 10820/18424 (observations 486855-486900/829080) loss: 4.05625\n",
      "2025-02-28 16:28:08 | Batch 10830/18424 (observations 487305-487350/829080) loss: 4.04375\n",
      "2025-02-28 16:28:29 | Batch 10840/18424 (observations 487755-487800/829080) loss: 4.078125\n",
      "2025-02-28 16:28:50 | Batch 10850/18424 (observations 488205-488250/829080) loss: 4.1046875\n",
      "2025-02-28 16:29:12 | Batch 10860/18424 (observations 488655-488700/829080) loss: 4.0765625\n",
      "2025-02-28 16:29:33 | Batch 10870/18424 (observations 489105-489150/829080) loss: 4.1015625\n",
      "2025-02-28 16:29:54 | Batch 10880/18424 (observations 489555-489600/829080) loss: 4.1140625\n",
      "2025-02-28 16:30:15 | Batch 10890/18424 (observations 490005-490050/829080) loss: 4.0796875\n",
      "2025-02-28 16:30:37 | Batch 10900/18424 (observations 490455-490500/829080) loss: 4.1140625\n",
      "2025-02-28 16:30:59 | Batch 10910/18424 (observations 490905-490950/829080) loss: 4.121875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_default_device(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m trainer \u001b[38;5;241m=\u001b[39m GPT1Trainer(config_test\u001b[38;5;241m.\u001b[39mtrainer)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\scher\\Repositories\\bettmensch.ai-examples\\.venv\\Lib\\site-packages\\bettmensch_ai_examples\\gpt_1\\src\\train.py:388\u001b[0m, in \u001b[0;36mGPT1Trainer.train\u001b[1;34m(self, train_loader, model, validation_loader, checkpoint)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_epochs\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# run training and retrieve loss averaged over last 1000 batches of\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# training split\u001b[39;00m\n\u001b[1;32m--> 388\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss_history\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\scher\\Repositories\\bettmensch.ai-examples\\.venv\\Lib\\site-packages\\bettmensch_ai_examples\\gpt_1\\src\\train.py:284\u001b[0m, in \u001b[0;36mGPT1Trainer.run_epoch\u001b[1;34m(self, data_loader, train)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# Gather data and report\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m%\u001b[39m display_step \u001b[38;5;241m==\u001b[39m (display_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    287\u001b[0m \n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# average loss over last display_step batches\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     step_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m display_step\n",
      "File \u001b[1;32mc:\\Users\\scher\\Repositories\\bettmensch.ai-examples\\.venv\\Lib\\site-packages\\torch\\utils\\_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resume_training = False\n",
    "\n",
    "if resume_training:\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    train_data = TokenizedBookCorpusOpenSplit(**config_test.data['train']['dataset'])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data, collate_fn=TokenizedBookCorpusOpenSplit.collate_batch, **config_test.data['train']['dataloader'],generator=torch.Generator(device=\"cuda\")\n",
    "    )\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    trainer = GPTTrainer.from_checkpoint(path=\"\", train_loader=train_loader)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
