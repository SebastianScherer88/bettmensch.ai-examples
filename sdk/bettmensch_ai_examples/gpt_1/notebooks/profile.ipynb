{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0221 23:54:46.703000 9440 torch\\distributed\\elastic\\multiprocessing\\redirects.py:27] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "c:\\Users\\scher\\Repositories\\bettmensch.ai-examples\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D50457590>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D50457590>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D50457590>\n",
      "Pipeline pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D50457590>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D50457590>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D50457590>\n",
      "Pipeline pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D50457590>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D50457590>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D50457590>\n",
      "Pipeline pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D50457590>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D50457590>\n",
      "Base Component pipeline context: <bettmensch_ai.pipelines.pipeline_context.PipelineContext object at 0x0000029D50457590>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from bettmensch_ai_examples.gpt_1.src.model import GPT1Core, DecoderLayer, GPT1Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_model(n, batch_size=5,layer_only: bool = True, use_gpu=False,sort_by=\"self_cpu_time_total\"):\n",
    "\n",
    "    mask = torch.ones((batch_size,512),dtype=torch.bool)\n",
    "\n",
    "    if layer_only:\n",
    "        inputs = torch.rand(batch_size, 512, 768,dtype=torch.half)\n",
    "        model = DecoderLayer()\n",
    "        model.set_nest_level()\n",
    "    else:\n",
    "        inputs = torch.randint(low=0,high=30000,size=(batch_size, 512))\n",
    "        model = GPT1Core(30000)\n",
    "        \n",
    "    if use_gpu:\n",
    "        gpu_device = torch.device(\"cuda\")\n",
    "        inputs = inputs.to(gpu_device)\n",
    "        mask = mask.to(gpu_device)\n",
    "        model.to(gpu_device)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            for k in range(n):\n",
    "                model(inputs, mask)\n",
    "\n",
    "    print(prof.key_averages().table(sort_by=sort_by, row_limit=550))\n",
    "\n",
    "    return prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer level comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                aten::addmm        88.82%       69.209s        88.83%       69.215s        1.730s       69.218s        88.83%       69.224s        1.731s            40  \n",
      "                  aten::bmm        10.37%        8.082s        10.40%        8.104s     405.196ms        8.088s        10.38%        8.107s     405.350ms            20  \n",
      "             aten::_softmax         0.15%     116.521ms         0.15%     116.521ms      11.652ms     116.900ms         0.15%     116.900ms      11.690ms            10  \n",
      "           aten::bernoulli_         0.12%      91.952ms         0.12%      92.545ms       1.851ms      98.042ms         0.13%      98.348ms       1.967ms            50  \n",
      "            model_inference         0.10%      81.014ms       100.00%       77.922s       77.922s      67.139ms         0.09%       77.924s       77.924s             1  \n",
      "                  aten::mul         0.06%      50.497ms         0.06%      50.497ms       1.010ms      52.665ms         0.07%      52.665ms       1.053ms            50  \n",
      "                 aten::gelu         0.06%      49.382ms         0.06%      49.382ms       4.938ms      51.055ms         0.07%      51.055ms       5.106ms            10  \n",
      "                 aten::div_         0.05%      38.885ms         0.05%      42.817ms     856.340us      33.037ms         0.04%      35.739ms     714.780us            50  \n",
      "                  aten::div         0.04%      31.263ms         0.04%      32.143ms       3.214ms      34.508ms         0.04%      35.775ms       3.578ms            10  \n",
      "                aten::copy_         0.04%      30.966ms         0.04%      30.966ms     182.153us      28.551ms         0.04%      28.551ms     167.947us           170  \n",
      "    aten::native_layer_norm         0.03%      21.496ms         0.03%      21.721ms       1.086ms      22.469ms         0.03%      24.030ms       1.202ms            20  \n",
      "               aten::select         0.03%      20.769ms         0.03%      22.185ms      15.406us       8.949ms         0.01%      13.198ms       9.165us          1440  \n",
      "                  aten::add         0.02%      17.302ms         0.02%      17.302ms     865.100us      16.501ms         0.02%      16.501ms     825.050us            20  \n",
      "         aten::masked_fill_         0.02%      12.957ms         0.02%      12.957ms       1.296ms      12.021ms         0.02%      12.021ms       1.202ms            10  \n",
      "               aten::matmul         0.01%       8.627ms        10.42%        8.116s     405.782ms       6.716ms         0.01%        8.117s     405.853ms            20  \n",
      "              aten::dropout         0.01%       6.400ms         0.25%     195.979ms       3.920ms       6.729ms         0.01%     195.271ms       3.905ms            50  \n",
      "               aten::linear         0.01%       6.101ms        88.84%       69.225s        1.731s       4.249ms         0.01%       69.232s        1.731s            40  \n",
      "                aten::empty         0.01%       4.376ms         0.01%       4.376ms      19.026us       3.940ms         0.01%       3.940ms      17.130us           230  \n",
      "                aten::clone         0.00%       3.244ms         0.04%      28.140ms     469.000us       2.117ms         0.00%      26.529ms     442.150us            60  \n",
      "             aten::_to_copy         0.00%       3.085ms         0.01%       5.514ms      78.771us       1.445ms         0.00%       3.584ms      51.200us            70  \n",
      "          aten::bitwise_and         0.00%       2.853ms         0.00%       2.853ms     285.300us       4.492ms         0.01%       4.492ms     449.200us            10  \n",
      "               aten::expand         0.00%       2.530ms         0.00%       2.608ms      26.080us       4.102ms         0.01%       4.799ms      47.990us           100  \n",
      "                   aten::eq         0.00%       2.471ms         0.00%       2.471ms     247.100us       5.270ms         0.01%       5.270ms     527.000us            10  \n",
      "           aten::as_strided         0.00%       2.221ms         0.00%       2.221ms       1.314us       6.391ms         0.01%       6.391ms       3.782us          1690  \n",
      "                 aten::tril         0.00%       2.191ms         0.00%       2.191ms     219.100us       1.883ms         0.00%       1.883ms     188.300us            10  \n",
      "          aten::masked_fill         0.00%       2.115ms         0.04%      29.138ms       2.914ms       1.290ms         0.00%      28.282ms       2.828ms            10  \n",
      "            aten::unsqueeze         0.00%       2.040ms         0.00%       2.557ms      85.233us       1.726ms         0.00%       2.538ms      84.600us            30  \n",
      "           aten::empty_like         0.00%       1.969ms         0.01%       5.489ms      49.900us       1.552ms         0.00%       4.549ms      41.355us           110  \n",
      "            aten::transpose         0.00%       1.964ms         0.00%       2.154ms      23.933us       1.509ms         0.00%       2.048ms      22.756us            90  \n",
      "                 aten::view         0.00%       1.934ms         0.00%       1.934ms       9.670us       2.542ms         0.00%       2.542ms      12.710us           200  \n",
      "              aten::reshape         0.00%       1.626ms         0.00%       2.293ms      28.663us       2.057ms         0.00%       3.000ms      37.500us            80  \n",
      "                aten::split         0.00%       1.491ms         0.00%       3.187ms     318.700us       1.291ms         0.00%       3.578ms     357.800us            10  \n",
      "                aten::fill_         0.00%       1.464ms         0.00%       1.464ms     146.400us       1.245ms         0.00%       1.245ms     124.500us            10  \n",
      "           aten::layer_norm         0.00%       1.289ms         0.03%      23.010ms       1.151ms       1.164ms         0.00%      25.194ms       1.260ms            20  \n",
      "                    aten::t         0.00%       1.257ms         0.00%       2.156ms      53.900us       1.272ms         0.00%       2.371ms      59.275us            40  \n",
      "               aten::narrow         0.00%       1.232ms         0.00%       1.696ms      56.533us       1.842ms         0.00%       2.287ms      76.233us            30  \n",
      "              aten::softmax         0.00%       1.110ms         0.15%     117.631ms      11.763ms     701.000us         0.00%     117.601ms      11.760ms            10  \n",
      "                   aten::to         0.00%       1.046ms         0.01%       6.560ms      93.714us       1.577ms         0.00%       5.161ms      73.729us            70  \n",
      "           aten::contiguous         0.00%     790.000us         0.02%      15.246ms     304.920us     796.000us         0.00%      15.094ms     301.880us            50  \n",
      "              aten::__and__         0.00%     729.000us         0.00%       3.582ms     358.200us     515.000us         0.00%       5.007ms     500.700us            10  \n",
      "                 aten::ones         0.00%     720.000us         0.00%       2.336ms     233.600us     556.000us         0.00%       2.067ms     206.700us            10  \n",
      "         aten::_unsafe_view         0.00%     669.000us         0.00%     669.000us      33.450us     393.000us         0.00%     393.000us      19.650us            20  \n",
      "                aten::slice         0.00%     444.000us         0.00%     464.000us      15.467us     351.000us         0.00%     445.000us      14.833us            30  \n",
      "        aten::empty_strided         0.00%     245.000us         0.00%     245.000us       3.500us     352.000us         0.00%     352.000us       5.029us            70  \n",
      "         aten::resolve_conj         0.00%      17.000us         0.00%      17.000us       0.011us       5.878ms         0.01%       5.878ms       3.768us          1560  \n",
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 77.922s\n",
      "Self CUDA time total: 77.924s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prof = time_model(n=10,batch_size=2,layer_only=True, use_gpu=False,sort_by=\"self_cpu_time_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                aten::addmm         1.12%      28.835ms         1.38%      35.431ms      88.578us        1.068s        41.16%        1.076s       2.689ms           400  \n",
      "       aten::native_dropout         0.73%      18.871ms         1.31%      33.697ms      67.394us     280.123ms        10.80%     318.371ms     636.742us           500  \n",
      "                aten::copy_        85.10%        2.190s        85.10%        2.190s       2.747ms     250.281ms         9.65%     250.281ms     314.029us           797  \n",
      "                  aten::bmm         0.34%       8.798ms         0.34%       8.798ms      43.990us     173.149ms         6.68%     173.149ms     865.745us           200  \n",
      "         aten::masked_fill_         0.10%       2.511ms         0.14%       3.647ms      36.470us     153.662ms         5.92%     154.048ms       1.540ms           100  \n",
      "                  aten::div         0.08%       1.994ms         0.08%       1.994ms      19.940us     142.899ms         5.51%     142.899ms       1.429ms           100  \n",
      "             aten::_softmax         0.07%       1.724ms         0.07%       1.724ms      17.240us     142.397ms         5.49%     142.397ms       1.424ms           100  \n",
      "                 aten::gelu         0.07%       1.837ms         0.07%       1.837ms      18.370us      69.280ms         2.67%      69.280ms     692.800us           100  \n",
      "                  aten::add         0.12%       3.144ms         0.12%       3.144ms      15.720us      59.336ms         2.29%      59.336ms     296.680us           200  \n",
      "           aten::empty_like         0.72%      18.595ms         0.88%      22.553ms      14.096us      48.320ms         1.86%      55.763ms      34.852us          1600  \n",
      "    aten::native_layer_norm         0.67%      17.296ms         0.72%      18.589ms      92.945us      35.924ms         1.39%      37.250ms     186.250us           200  \n",
      "                    aten::t         0.26%       6.740ms         0.51%      13.014ms      32.535us      17.676ms         0.68%      27.680ms      69.200us           400  \n",
      "            model_inference         3.84%      98.717ms       100.00%        2.573s        2.573s      16.627ms         0.64%        2.594s        2.594s             1  \n",
      "          aten::bitwise_and         0.22%       5.645ms         0.22%       5.645ms      56.450us      15.950ms         0.61%      15.950ms     159.500us           100  \n",
      "              aten::reshape         0.38%       9.865ms         0.47%      11.999ms      14.999us      14.019ms         0.54%      17.426ms      21.782us           800  \n",
      "                aten::clone         0.50%      12.799ms         1.04%      26.750ms      44.583us      13.233ms         0.51%     269.560ms     449.267us           600  \n",
      "            aten::transpose         0.48%      12.334ms         0.49%      12.651ms      14.057us      10.577ms         0.41%      12.378ms      13.753us           900  \n",
      "               aten::expand         0.63%      16.217ms         0.64%      16.340ms      14.855us       8.194ms         0.32%      12.539ms      11.399us          1100  \n",
      "                 aten::ones         0.13%       3.221ms         0.30%       7.615ms      76.150us       7.767ms         0.30%       8.031ms      80.310us           100  \n",
      "                aten::split         0.14%       3.555ms         0.39%       9.949ms      99.490us       7.547ms         0.29%      10.632ms     106.320us           100  \n",
      "           aten::as_strided         0.03%     700.000us         0.03%     700.000us       0.272us       6.971ms         0.27%       6.971ms       2.708us          2574  \n",
      "               aten::linear         0.85%      21.989ms         3.06%      78.703ms     196.757us       6.149ms         0.24%        1.114s       2.784ms           400  \n",
      "                aten::empty         0.12%       2.993ms         0.12%       2.993ms       2.338us       5.940ms         0.23%       5.940ms       4.641us          1280  \n",
      "                   aten::eq         0.08%       1.950ms         0.08%       1.950ms      19.500us       5.900ms         0.23%       5.900ms      59.000us           100  \n",
      "                 aten::view         0.18%       4.557ms         0.18%       4.557ms       2.280us       5.016ms         0.19%       5.016ms       2.509us          1999  \n",
      "            aten::unsqueeze         0.18%       4.536ms         0.18%       4.705ms      15.683us       4.361ms         0.17%       4.715ms      15.717us           300  \n",
      "             aten::_to_copy         0.35%       9.013ms        85.24%        2.193s      10.966ms       4.201ms         0.16%      16.681ms      83.405us           200  \n",
      "               aten::matmul         0.55%      14.277ms         1.35%      34.839ms     174.195us       4.110ms         0.16%     194.493ms     972.465us           200  \n",
      "        aten::empty_strided         0.11%       2.758ms         0.11%       2.758ms       2.329us       3.435ms         0.13%       3.435ms       2.901us          1184  \n",
      "                   aten::to         0.10%       2.640ms        85.34%        2.196s       7.320ms       3.201ms         0.12%      19.882ms      66.273us           300  \n",
      "           aten::contiguous         0.20%       5.204ms         1.05%      27.016ms      54.032us       2.326ms         0.09%     122.955ms     245.910us           500  \n",
      "               aten::narrow         0.12%       3.152ms         0.25%       6.394ms      21.313us       1.423ms         0.05%       3.085ms      10.283us           300  \n",
      "              aten::dropout         0.24%       6.158ms         1.55%      39.855ms      79.710us       1.382ms         0.05%     319.753ms     639.506us           500  \n",
      "                aten::slice         0.12%       3.143ms         0.13%       3.242ms      10.807us       1.191ms         0.05%       1.662ms       5.540us           300  \n",
      "              aten::__and__         0.06%       1.569ms         0.28%       7.214ms      72.140us       1.087ms         0.04%      17.037ms     170.370us           100  \n",
      "          aten::masked_fill         0.18%       4.547ms         0.59%      15.298ms     152.980us     817.000us         0.03%     304.805ms       3.048ms           100  \n",
      "           aten::layer_norm         0.12%       3.009ms         0.84%      21.598ms     107.990us     522.000us         0.02%      37.772ms     188.860us           200  \n",
      "                 aten::tril         0.48%      12.387ms         0.48%      12.387ms     123.870us     375.000us         0.01%     375.000us       3.750us           100  \n",
      "         aten::_unsafe_view         0.02%     527.000us         0.02%     527.000us       2.635us     266.000us         0.01%     266.000us       1.330us           200  \n",
      "              aten::softmax         0.05%       1.178ms         0.11%       2.902ms      29.020us     263.000us         0.01%     142.660ms       1.427ms           100  \n",
      "                aten::fill_         0.16%       4.119ms         0.16%       4.119ms      41.190us     137.000us         0.01%     137.000us       1.370us           100  \n",
      "           aten::as_strided         0.00%       8.000us         0.00%       8.000us       0.308us       0.000us         0.00%       0.000us       0.000us            26  \n",
      "                aten::empty         0.00%      50.000us         0.00%      50.000us       2.500us       0.000us         0.00%       0.000us       0.000us            20  \n",
      "        aten::empty_strided         0.00%      37.000us         0.00%      37.000us       2.312us       0.000us         0.00%       0.000us       0.000us            16  \n",
      "                 aten::view         0.00%       1.000us         0.00%       1.000us       1.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                aten::copy_         0.01%     217.000us         0.01%     217.000us      72.333us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.573s\n",
      "Self CUDA time total: 2.594s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prof = time_model(n=100,batch_size=16,layer_only=True, use_gpu=True,sort_by=\"self_cuda_time_total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model level comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                aten::addmm         1.29%     581.193ms         1.99%     898.208ms     187.127us       17.981s        39.70%       18.064s       3.763ms          4800  \n",
      "       aten::native_dropout         0.81%     365.363ms         1.26%     569.903ms      93.427us        6.785s        14.98%        7.218s       1.183ms          6100  \n",
      "                aten::copy_        81.80%       36.947s        81.80%       36.947s       3.862ms        4.710s        10.40%        4.710s     492.288us          9567  \n",
      "                  aten::bmm         0.26%     118.235ms         0.26%     118.235ms      49.265us        3.107s         6.86%        3.107s       1.295ms          2400  \n",
      "             aten::_softmax         0.10%      43.625ms         0.10%      43.625ms      36.354us        2.649s         5.85%        2.649s       2.208ms          1200  \n",
      "                  aten::div         0.08%      35.403ms         0.08%      35.403ms      29.503us        2.467s         5.45%        2.467s       2.056ms          1200  \n",
      "         aten::masked_fill_         0.06%      28.143ms         0.09%      39.406ms      32.838us        1.862s         4.11%        1.867s       1.556ms          1200  \n",
      "                 aten::gelu         0.30%     137.094ms         0.30%     137.094ms     114.245us        1.231s         2.72%        1.231s       1.026ms          1200  \n",
      "                  aten::add         0.30%     135.405ms         0.30%     135.405ms      54.162us        1.186s         2.62%        1.186s     474.233us          2500  \n",
      "    aten::native_layer_norm         1.00%     451.821ms         1.03%     467.418ms     194.757us     748.682ms         1.65%     765.380ms     318.908us          2400  \n",
      "           aten::empty_like         0.62%     281.432ms         0.77%     349.806ms      18.031us     507.733ms         1.12%     641.050ms      33.044us         19400  \n",
      "            model_inference         5.63%        2.542s       100.00%       45.165s       45.165s     221.672ms         0.49%       45.288s       45.288s             1  \n",
      "                    aten::t         0.60%     271.951ms         0.76%     344.745ms      71.822us     168.018ms         0.37%     283.223ms      59.005us          4800  \n",
      "          aten::bitwise_and         0.16%      73.607ms         0.16%      73.607ms      61.339us     160.796ms         0.36%     160.796ms     133.997us          1200  \n",
      "              aten::reshape         0.44%     199.460ms         0.52%     235.239ms      24.251us     159.733ms         0.35%     208.820ms      21.528us          9700  \n",
      "                aten::clone         0.54%     241.656ms         1.04%     470.405ms      65.334us     130.632ms         0.29%        4.908s     681.702us          7200  \n",
      "            aten::transpose         0.37%     165.901ms         0.38%     169.669ms      15.710us     120.452ms         0.27%     145.860ms      13.506us         10800  \n",
      "        aten::empty_strided         0.11%      50.893ms         0.11%      50.893ms       3.537us      93.841ms         0.21%      93.841ms       6.522us         14389  \n",
      "                aten::split         0.09%      42.496ms         0.28%     124.701ms     103.918us      87.959ms         0.19%     128.352ms     106.960us          1200  \n",
      "               aten::expand         1.09%     491.743ms         1.09%     493.816ms      37.410us      86.860ms         0.19%     128.884ms       9.764us         13200  \n",
      "           aten::as_strided         0.02%       9.181ms         0.02%       9.181ms       0.297us      79.688ms         0.18%      79.688ms       2.574us         30961  \n",
      "               aten::linear         0.78%     353.623ms         3.93%        1.775s     369.797us      77.743ms         0.17%       18.490s       3.852ms          4800  \n",
      "                   aten::eq         0.08%      34.091ms         0.08%      34.091ms      28.409us      76.107ms         0.17%      76.107ms      63.422us          1200  \n",
      "                aten::empty         0.09%      42.580ms         0.09%      42.580ms       2.709us      72.415ms         0.16%      72.415ms       4.607us         15718  \n",
      "                 aten::view         0.14%      64.876ms         0.14%      64.876ms       2.684us      69.281ms         0.15%      69.281ms       2.866us         24170  \n",
      "         aten::index_select         0.08%      35.990ms         0.08%      37.098ms     185.490us      66.666ms         0.15%      73.440ms     367.200us           200  \n",
      "                 aten::ones         0.37%     165.180ms         0.51%     229.691ms     191.409us      64.335ms         0.14%      69.011ms      57.509us          1200  \n",
      "            aten::unsqueeze         0.17%      75.581ms         0.17%      77.868ms      21.045us      55.670ms         0.12%      61.171ms      16.533us          3700  \n",
      "             aten::_to_copy         0.55%     250.269ms        82.19%       37.123s      15.468ms      53.360ms         0.12%     214.668ms      89.445us          2400  \n",
      "                   aten::to         0.13%      57.356ms        82.32%       37.181s      10.328ms      38.481ms         0.08%     253.149ms      70.319us          3600  \n",
      "               aten::matmul         0.41%     183.668ms         1.14%     514.362ms     214.317us      36.288ms         0.08%        3.323s       1.385ms          2400  \n",
      "           aten::contiguous         0.14%      62.238ms         1.04%     469.860ms      78.310us      26.568ms         0.06%        2.333s     388.850us          6000  \n",
      "               aten::narrow         0.09%      41.230ms         0.18%      82.205ms      22.835us      19.034ms         0.04%      40.393ms      11.220us          3600  \n",
      "              aten::dropout         0.26%     118.402ms         1.52%     688.305ms     112.837us      17.847ms         0.04%        7.236s       1.186ms          6100  \n",
      "                aten::slice         0.09%      39.666ms         0.09%      40.975ms      11.382us      14.604ms         0.03%      21.359ms       5.933us          3600  \n",
      "              aten::__and__         0.05%      20.376ms         0.21%      93.983ms      78.319us      14.471ms         0.03%     175.267ms     146.056us          1200  \n",
      "          aten::masked_fill         0.14%      63.084ms         0.43%     193.546ms     161.288us      10.060ms         0.02%        4.493s       3.744ms          1200  \n",
      "                 aten::tril         0.33%     149.187ms         0.33%     149.187ms     124.530us       6.985ms         0.02%       6.985ms       5.831us          1198  \n",
      "              aten::resize_         0.00%     756.000us         0.00%     756.000us       3.780us       6.439ms         0.01%       6.439ms      32.195us           200  \n",
      "           aten::layer_norm         0.07%      32.127ms         1.11%     499.545ms     208.144us       6.375ms         0.01%     771.755ms     321.565us          2400  \n",
      "              aten::softmax         0.19%      85.274ms         0.29%     128.899ms     107.416us       3.383ms         0.01%        2.652s       2.210ms          1200  \n",
      "         aten::_unsafe_view         0.01%       6.301ms         0.01%       6.301ms       2.625us       3.215ms         0.01%       3.215ms       1.340us          2400  \n",
      "                aten::fill_         0.13%      60.896ms         0.13%      60.896ms      50.747us       3.044ms         0.01%       3.044ms       2.537us          1200  \n",
      "            aten::embedding         0.01%       5.601ms         0.10%      43.843ms     219.215us       1.205ms         0.00%      75.362ms     376.810us           200  \n",
      "        aten::empty_strided         0.00%     363.000us         0.00%     363.000us       1.720us       0.000us         0.00%       0.000us       0.000us           211  \n",
      "           aten::as_strided         0.00%     256.000us         0.00%     256.000us       0.755us       0.000us         0.00%       0.000us       0.000us           339  \n",
      "                aten::empty         0.00%     338.000us         0.00%     338.000us       4.122us       0.000us         0.00%       0.000us       0.000us            82  \n",
      "                 aten::view         0.00%      48.000us         0.00%      48.000us       1.600us       0.000us         0.00%       0.000us       0.000us            30  \n",
      "                aten::copy_         0.01%       2.374ms         0.01%       2.374ms      71.939us       0.000us         0.00%       0.000us       0.000us            33  \n",
      "                 aten::tril         0.00%     252.000us         0.00%     252.000us     126.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 45.165s\n",
      "Self CUDA time total: 45.288s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.profiler.profiler.profile at 0x22cb5418f10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_model(n=100,batch_size=16,layer_only=False,use_gpu=True,sort_by=\"self_cuda_time_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                aten::addmm         2.00%     863.521ms         2.46%        1.061s     220.938us       17.226s        39.94%       17.313s       3.607ms          4800  \n",
      "       aten::native_dropout         1.56%     674.079ms         2.81%        1.210s     198.343us        6.467s        14.99%        6.924s       1.135ms          6100  \n",
      "                aten::copy_        71.44%       30.815s        71.44%       30.815s       3.217ms        4.537s        10.52%        4.537s     473.714us          9578  \n",
      "             aten::_softmax         0.10%      42.082ms         0.10%      42.082ms      35.068us        3.425s         7.94%        3.425s       2.854ms          1200  \n",
      "                  aten::bmm         0.65%     278.521ms         0.65%     278.521ms     116.050us        3.164s         7.33%        3.164s       1.318ms          2400  \n",
      "         aten::masked_fill_         0.14%      60.046ms         0.19%      81.623ms      68.019us        2.641s         6.12%        2.646s       2.205ms          1200  \n",
      "                 aten::gelu         0.14%      60.035ms         0.14%      60.035ms      50.029us        1.181s         2.74%        1.181s     983.992us          1200  \n",
      "                  aten::add         0.43%     184.740ms         0.43%     184.740ms      73.896us        1.066s         2.47%        1.066s     426.411us          2500  \n",
      "    aten::native_layer_norm         2.29%     989.548ms         2.34%        1.007s     419.774us     724.003ms         1.68%     742.179ms     309.241us          2400  \n",
      "           aten::empty_like         1.33%     571.792ms         1.58%     680.779ms      35.092us     496.075ms         1.15%     736.452ms      37.961us         19400  \n",
      "            model_inference         8.06%        3.476s       100.00%       43.133s       43.133s     231.573ms         0.54%       43.135s       43.135s             1  \n",
      "              aten::reshape         0.35%     152.732ms         0.45%     192.342ms      19.829us     169.801ms         0.39%     218.639ms      22.540us          9700  \n",
      "          aten::bitwise_and         0.17%      72.789ms         0.17%      72.789ms      60.657us     163.541ms         0.38%     163.541ms     136.284us          1200  \n",
      "                    aten::t         0.30%     131.226ms         0.77%     330.003ms      68.751us     159.435ms         0.37%     274.362ms      57.159us          4800  \n",
      "        aten::empty_strided         0.16%      68.267ms         0.16%      68.267ms       4.734us     144.690ms         0.34%     144.690ms      10.033us         14422  \n",
      "                aten::empty         0.16%      67.206ms         0.16%      67.206ms       4.298us     136.182ms         0.32%     136.182ms       8.710us         15635  \n",
      "                aten::clone         0.72%     309.188ms         1.36%     587.880ms      81.650us     135.036ms         0.31%        4.809s     667.852us          7200  \n",
      "            aten::transpose         0.86%     370.415ms         0.87%     375.622ms      34.780us     120.272ms         0.28%     150.244ms      13.911us         10800  \n",
      "               aten::expand         0.76%     326.590ms         0.76%     329.116ms      24.933us      94.387ms         0.22%     132.622ms      10.047us         13200  \n",
      "                aten::split         0.14%      61.491ms         0.44%     190.296ms     158.580us      93.057ms         0.22%     137.583ms     114.653us          1200  \n",
      "               aten::linear         2.16%     933.146ms         5.68%        2.449s     510.169us      83.853ms         0.19%       17.742s       3.696ms          4800  \n",
      "           aten::as_strided         0.03%      12.017ms         0.03%      12.017ms       0.388us      79.857ms         0.19%      79.857ms       2.576us         31006  \n",
      "                   aten::eq         0.11%      46.609ms         0.11%      46.609ms      38.841us      73.933ms         0.17%      73.933ms      61.611us          1200  \n",
      "                 aten::view         0.17%      72.991ms         0.17%      72.991ms       3.021us      71.845ms         0.17%      71.845ms       2.973us         24163  \n",
      "                 aten::ones         0.56%     240.076ms         0.72%     309.078ms     257.565us      62.595ms         0.15%      66.678ms      55.565us          1200  \n",
      "         aten::index_select         0.08%      34.235ms         0.08%      35.176ms     351.760us      60.608ms         0.14%      67.753ms     677.530us           100  \n",
      "            aten::unsqueeze         0.70%     301.429ms         0.70%     304.003ms      84.445us      57.142ms         0.13%      62.664ms      17.407us          3600  \n",
      "             aten::_to_copy         0.62%     268.509ms        71.78%       30.959s      12.900ms      56.193ms         0.13%     226.858ms      94.524us          2400  \n",
      "               aten::matmul         0.87%     377.004ms         1.91%     824.674ms     343.614us      39.490ms         0.09%        3.390s       1.412ms          2400  \n",
      "                   aten::to         0.08%      35.603ms        71.86%       30.995s       8.610ms      31.931ms         0.07%     258.789ms      71.886us          3600  \n",
      "           aten::contiguous         0.38%     165.706ms         1.37%     589.991ms      98.332us      23.719ms         0.05%        2.365s     394.192us          6000  \n",
      "               aten::narrow         0.13%      55.095ms         0.30%     128.805ms      35.779us      22.272ms         0.05%      44.526ms      12.368us          3600  \n",
      "              aten::dropout         0.94%     403.881ms         3.74%        1.614s     264.553us      18.754ms         0.04%        6.942s       1.138ms          6100  \n",
      "              aten::__and__         0.05%      23.645ms         0.22%      96.434ms      80.362us      16.709ms         0.04%     180.250ms     150.208us          1200  \n",
      "                aten::slice         0.17%      71.899ms         0.17%      73.710ms      20.475us      16.126ms         0.04%      22.254ms       6.182us          3600  \n",
      "          aten::masked_fill         0.21%      90.012ms         0.84%     364.037ms     303.364us      10.889ms         0.03%        5.137s       4.281ms          1200  \n",
      "                 aten::tril         0.34%     145.331ms         0.34%     145.331ms     121.514us       9.098ms         0.02%       9.098ms       7.607us          1196  \n",
      "           aten::layer_norm         0.41%     175.930ms         2.74%        1.183s     493.078us       7.459ms         0.02%     749.638ms     312.349us          2400  \n",
      "              aten::resize_         0.00%     653.000us         0.00%     653.000us       6.530us       6.814ms         0.02%       6.814ms      68.140us           100  \n",
      "         aten::_unsafe_view         0.02%       7.022ms         0.02%       7.022ms       2.926us       3.656ms         0.01%       3.656ms       1.523us          2400  \n",
      "              aten::softmax         0.05%      23.141ms         0.15%      65.223ms      54.352us       3.441ms         0.01%        3.428s       2.857ms          1200  \n",
      "                aten::fill_         0.15%      65.561ms         0.15%      65.561ms      54.634us       2.376ms         0.01%       2.376ms       1.980us          1200  \n",
      "            aten::embedding         0.01%       4.674ms         0.10%      41.201ms     412.010us       1.262ms         0.00%      69.942ms     699.420us           100  \n",
      "           aten::as_strided         0.00%     101.000us         0.00%     101.000us       0.521us       0.000us         0.00%       0.000us       0.000us           194  \n",
      "                 aten::view         0.00%      60.000us         0.00%      60.000us       1.622us       0.000us         0.00%       0.000us       0.000us            37  \n",
      "                aten::empty         0.00%     177.000us         0.00%     177.000us       2.723us       0.000us         0.00%       0.000us       0.000us            65  \n",
      "        aten::empty_strided         0.00%     324.000us         0.00%     324.000us       1.820us       0.000us         0.00%       0.000us       0.000us           178  \n",
      "                aten::copy_         0.00%       1.519ms         0.00%       1.519ms      69.045us       0.000us         0.00%       0.000us       0.000us            22  \n",
      "                 aten::tril         0.00%     498.000us         0.00%     498.000us     124.500us       0.000us         0.00%       0.000us       0.000us             4  \n",
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 43.133s\n",
      "Self CUDA time total: 43.135s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.profiler.profiler.profile at 0x213c375f450>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_model(n=100,batch_size=16,layer_only=False,karpathy=True,use_gpu=True,sort_by=\"self_cuda_time_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512, 768]),\n",
       " tensor([[[-0.5049, -2.5391,  0.5952,  ..., -0.0470, -0.4937,  1.8857],\n",
       "          [ 0.3708, -0.8301,  2.7305,  ..., -0.0000,  0.7598,  0.1093],\n",
       "          [ 0.0000, -0.1092, -0.3325,  ...,  1.6611, -1.0459, -0.2112],\n",
       "          ...,\n",
       "          [ 2.0527,  0.0000, -0.3018,  ...,  0.0000,  0.0706,  0.1324],\n",
       "          [ 1.6699, -1.2598,  0.1018,  ..., -1.2334,  1.2178, -1.6279],\n",
       "          [ 1.1924,  0.6562,  0.0355,  ...,  0.0000, -0.0049,  0.3257]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<NativeDropoutBackward0>))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_device = torch.device(\"cuda\")\n",
    "\n",
    "model = DecoderLayer()\n",
    "model.set_nest_level()\n",
    "model.to(gpu_device)\n",
    "\n",
    "inputs = torch.rand(1, 512, 768,dtype=torch.half).to(gpu_device)\n",
    "mask = torch.ones((1,512),dtype=torch.bool).to(gpu_device)\n",
    "\n",
    "outputs = model(inputs,mask)\n",
    "outputs.size(), outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512, 768]),\n",
       " tensor([[[-0.7222, -0.0000,  0.4094,  ...,  2.3184,  0.9126, -0.3777],\n",
       "          [-2.1016,  0.3618,  0.2703,  ...,  0.1775,  0.0360, -0.0820],\n",
       "          [ 0.5449,  0.2352, -0.0000,  ...,  0.0692, -0.9214, -0.6865],\n",
       "          ...,\n",
       "          [ 0.6113,  0.2185, -0.2742,  ..., -0.1758, -0.0150, -0.0599],\n",
       "          [-0.1068,  0.9580,  1.0029,  ...,  0.0000, -0.1261,  0.1019],\n",
       "          [ 3.0938, -0.4995, -0.4680,  ..., -0.6748,  0.0461,  0.3140]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<NativeDropoutBackward0>))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_device = torch.device(\"cuda\")\n",
    "\n",
    "model = GPT1Core(30000)\n",
    "model.to(gpu_device)\n",
    "\n",
    "inputs = torch.randint(low=0, high=30000, size=(1, 512)).to(gpu_device)\n",
    "mask = torch.ones((1,512),dtype=torch.bool).to(gpu_device)\n",
    "\n",
    "outputs = model(inputs,mask)\n",
    "outputs.size(), outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512, 30000]),\n",
       " tensor([[[-0.0814,  0.4971, -0.1242,  ..., -0.2145,  0.0060,  0.5791],\n",
       "          [-0.2820,  0.0219, -0.1628,  ...,  0.8433, -0.1349,  0.4685],\n",
       "          [-0.3379, -1.1406,  0.3604,  ...,  1.0996,  0.2864,  0.0953],\n",
       "          ...,\n",
       "          [ 1.2432, -0.1678,  0.4783,  ...,  1.0586,  0.6890, -0.1908],\n",
       "          [-0.6265,  0.5337, -0.2869,  ..., -0.2651, -0.6992,  0.1315],\n",
       "          [ 0.1234, -0.1227, -0.5156,  ...,  0.1487, -0.5483,  0.1032]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_device = torch.device(\"cuda\")\n",
    "\n",
    "model = GPT1Pretrain(30000)\n",
    "model.to(gpu_device)\n",
    "\n",
    "inputs = torch.randint(low=0, high=30000, size=(1, 512)).to(gpu_device)\n",
    "mask = torch.ones((1,512),dtype=torch.bool).to(gpu_device)\n",
    "\n",
    "outputs, loss = model(inputs,mask)\n",
    "outputs.size(), outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
